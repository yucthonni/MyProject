{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SAC import SAC\n",
    "from buffer import ReplayBuffer\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from reward_env import RewardEnv\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=RewardEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim=env.observation_space.shape[0]\n",
    "action_dim=env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer=ReplayBuffer(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 9806.42it/s]\n"
     ]
    }
   ],
   "source": [
    "pb=tqdm(range(100))\n",
    "for i in pb:\n",
    "    s=env.reset()\n",
    "    d=False\n",
    "    while not d:\n",
    "        a=env.action_space.sample()\n",
    "        s_,r,d,_=env.step(a)\n",
    "        replay_buffer.store(state=s,action=a,log_prob=None,next_state=s_,reward=r,state_value=None,done=d)\n",
    "        s=s_\n",
    "    pb.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac=SAC(30,1,32,1,replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/tools/DR/MyProject/RILE/SAC.py:258: UserWarning: Using a target size (torch.Size([64, 64])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  q_loss=F.mse_loss(q_value.view(-1),q_hat)\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 437.56it/s]\n"
     ]
    }
   ],
   "source": [
    "pb=tqdm(range(1000))\n",
    "for _ in pb:\n",
    "    sac.update()\n",
    "    pb.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=sac.replay_buffer.sample(2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-229001.6406, -473013.7500, -299890.8125,  379988.1562, -253203.0312,\n",
       "         393275.4688, -521069.6875,   31598.9180, -105671.4219,  253317.3281,\n",
       "        -919356.4375,  210842.7812, -269445.9375, -313047.0000,  886112.9375,\n",
       "          31573.4316,  117543.6172,  -36410.7461, -939118.4375,  599524.5625,\n",
       "         619710.1875,  317123.2500,  511041.7500,  603499.1875,  699835.9375,\n",
       "         986618.5625, -762467.4375,  209534.0156,  276026.9375,  893173.6250])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac.replay_buffer.state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self,input_dim,hidden_dim):\n",
    "#         super(Discriminator,self).__init__()\n",
    "#         self.discriminator=nn.Sequential(\n",
    "#             nn.Linear(input_dim,hidden_dim),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_dim,hidden_dim),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_dim,1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         x=self.discriminator(x)\n",
    "#         return nn.functional.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=Discriminator(31,32,64,replay_buffer,replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.collect_dist(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6632], grad_fn=<UnbindBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(D.model.discriminator(D.expert_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 786.09it/s]\n"
     ]
    }
   ],
   "source": [
    "D.update(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa=torch.stack([torch.cat((replay_buffer.state[i],replay_buffer.action[i]),-1) for i in index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5205],\n",
       "        [0.4943]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.model(sa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
