{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 01:58:45.389633: I tensorflow/stream_executor/platform/default/dso_loader.cc:50] Successfully opened dynamic library libcudart.so.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from specbuffer import SpecReplayBuffer\n",
    "from buffer import ReplayBuffer\n",
    "from PPOee import PPO\n",
    "import gym\n",
    "from CustomEnv import CustomEnv\n",
    "from Student_Agent import StudentAgent\n",
    "from TeacherAgent import TeacherAgent\n",
    "from ExpertTrajectory import ExpertTrajectory\n",
    "\n",
    "import contextlib\n",
    "import network_sim\n",
    "from stable_baselines3 import PPO as sb3ppo\n",
    "import pickle\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'specbuffer' from '/home/tools/DR/MyProject/RILE/specbuffer.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=importlib.import_module('specbuffer','SpecReplayBuffer')\n",
    "importlib.reload(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History length: 10\n",
      "Features: ['sent latency inflation', 'latency ratio', 'send ratio']\n",
      "Getting min obs for ['sent latency inflation', 'latency ratio', 'send ratio']\n"
     ]
    }
   ],
   "source": [
    "env=CustomEnv('PccNs-v0',1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "et=ExpertTrajectory(1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [00:00, 481.51it/s]                     \n"
     ]
    }
   ],
   "source": [
    "et.load_expert_model('verygood.zip')\n",
    "et.generate_trajectory(env,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(StudentAgent):\n",
    "    def __init__(self, state_dim, action_dim, env):\n",
    "        super().__init__(state_dim, action_dim, env)\n",
    "        \n",
    "    def generate_trajectory(self, step: int):\n",
    "        pb=tqdm(range(step))\n",
    "        for _ in pb:\n",
    "            s=self.env.reset()\n",
    "            d=False\n",
    "            while not d:\n",
    "                a,action,l,v=self.model.select_action(s)\n",
    "                s_,r,d,_=self.env.step(a)\n",
    "                self.model.buffer.store(s[-3:],a,l,s_,r,v,d)\n",
    "                s=s_\n",
    "            pb.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa=Student(30,1,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.replay_buffer.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "sa.generate_trajectory(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/data/envs/IL/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.97it/s]\n"
     ]
    }
   ],
   "source": [
    "sa.train(10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(TeacherAgent):\n",
    "    def __init__(self, state_dim, action_dim, env:CustomEnv, expert_trajectory):\n",
    "        super().__init__(state_dim, action_dim, env, expert_trajectory)\n",
    "        self.model = PPO(10, action_dim,\n",
    "                         256, self.replay_buffer)\n",
    "        \n",
    "    def ComputeReward(self):\n",
    "        pb=tqdm(range(min(self.trajectory_buffer.index,self.trajectory_buffer.buffer_size)))\n",
    "        for i in pb:\n",
    "            length=len(self.trajectory_buffer.state[0])\n",
    "            s=torch.FloatTensor(self.trajectory_buffer.get_state_padding(self.trajectory_buffer.state[int(i/length)],i%length,10,True)[1]).view(-1)\n",
    "            r=torch.FloatTensor(self.trajectory_buffer.get_reward_padding(self.trajectory_buffer.reward,i,10,length,True)[1]).view(-1)\n",
    "            reward,tensor_reward,l,v=self.model.select_action(r)\n",
    "            sa_pair=torch.cat((s.cuda(),tensor_reward.view(-1)),-1)\n",
    "            self.replay_buffer.store(\n",
    "                r,\n",
    "                reward,\n",
    "                l,\n",
    "                self.trajectory_buffer.next_state[i],\n",
    "                self.discriminator.model(sa_pair).detach().cpu().numpy(),\n",
    "                v,\n",
    "                self.trajectory_buffer.done[i]\n",
    "            )\n",
    "            self.trajectory_buffer.reward[i]=reward\n",
    "            pb.update()\n",
    "        self.discriminator.collect_expert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta=Teacher(30,1,env,et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1264.59it/s]\n"
     ]
    }
   ],
   "source": [
    "ta.ComputeReward()\n",
    "#BUG 这里有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.82it/s]\n"
     ]
    }
   ],
   "source": [
    "sa.train(10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<buffer.ReplayBuffer at 0x7f1d4c5b3040>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.model.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1210.70it/s]\n",
      "/home/data/envs/IL/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1024])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:24,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1228.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:12,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1217.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:08<00:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1223.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:10<00:07,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1257.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:13<00:03,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1228.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:16<00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1217.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:19<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1243.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:21,  1.81s/it]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1234.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:24,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing reward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:00<00:00, 1262.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator...\n",
      "Training PPO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "ta.train(10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "module=importlib.import_module('Discriminator','Discriminator.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=module.Discriminator(31,1,8,sa.replay_buffer,et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.collect_expert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.collect_dist(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.update(100,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
