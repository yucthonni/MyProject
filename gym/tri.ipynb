{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import network_sim\n",
    "from stable_baselines import PPO1\n",
    "from stable_baselines.common.policies import MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\"PccNs-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 0 ************\n",
      "Reward: 0.00, Ewma Reward: 0.00\n",
      "Reward: 648.69, Ewma Reward: 6.49\n",
      "Reward: 623.60, Ewma Reward: 12.66\n",
      "Reward: -167.26, Ewma Reward: 10.86\n",
      "Reward: -1251.23, Ewma Reward: -1.76\n",
      "Reward: 372.87, Ewma Reward: 1.98\n",
      "Reward: -114.01, Ewma Reward: 0.82\n",
      "Reward: 1228.92, Ewma Reward: 13.11\n",
      "Reward: 534.30, Ewma Reward: 18.32\n",
      "Reward: 681.73, Ewma Reward: 24.95\n",
      "Reward: 16.90, Ewma Reward: 24.87\n",
      "Reward: 957.58, Ewma Reward: 34.20\n",
      "Reward: 67.52, Ewma Reward: 34.53\n",
      "Reward: 197.69, Ewma Reward: 36.16\n",
      "Reward: 672.38, Ewma Reward: 42.52\n",
      "Reward: 1227.95, Ewma Reward: 54.38\n",
      "Reward: 273.09, Ewma Reward: 56.57\n",
      "Reward: 1366.96, Ewma Reward: 69.67\n",
      "Reward: 691.16, Ewma Reward: 75.89\n",
      "Reward: 448.46, Ewma Reward: 79.61\n",
      "Reward: 1360.93, Ewma Reward: 92.42\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00037 |      -0.01420 |    1080.16956 |       0.00106 |       1.42034\n",
      "     -0.00064 |      -0.01423 |    1040.21753 |       0.00360 |       1.42315\n",
      "     -0.00091 |      -0.01423 |    1004.79999 |       0.00238 |       1.42350\n",
      "     -0.00059 |      -0.01423 |     974.90698 |       0.00082 |       1.42336\n",
      "Evaluating losses...\n",
      "     -0.00090 |      -0.01424 |     958.10986 |       0.00061 |       1.42407\n",
      "------------------------------------\n",
      "| EpLenMean       | 400            |\n",
      "| EpRewMean       | 492            |\n",
      "| EpThisIter      | 20             |\n",
      "| EpisodesSoFar   | 20             |\n",
      "| TimeElapsed     | 8.26           |\n",
      "| TimestepsSoFar  | 8192           |\n",
      "| ev_tdlam_before | -0.00771       |\n",
      "| loss_ent        | 1.424071       |\n",
      "| loss_kl         | 0.000613751    |\n",
      "| loss_pol_entpen | -0.014240709   |\n",
      "| loss_pol_surr   | -0.00090206694 |\n",
      "| loss_vf_loss    | 958.10986      |\n",
      "------------------------------------\n",
      "********** Iteration 1 ************\n",
      "Reward: 864.36, Ewma Reward: 100.14\n",
      "Reward: 841.58, Ewma Reward: 107.56\n",
      "Reward: 843.08, Ewma Reward: 114.91\n",
      "Reward: 162.54, Ewma Reward: 115.39\n",
      "Reward: -584.13, Ewma Reward: 108.39\n",
      "Reward: 1333.79, Ewma Reward: 120.65\n",
      "Reward: 1301.66, Ewma Reward: 132.46\n",
      "Reward: -53.21, Ewma Reward: 130.60\n",
      "Reward: 86.49, Ewma Reward: 130.16\n",
      "Reward: 1418.07, Ewma Reward: 143.04\n",
      "Reward: 116.94, Ewma Reward: 142.78\n",
      "Reward: 374.09, Ewma Reward: 145.09\n",
      "Reward: -337.25, Ewma Reward: 140.27\n",
      "Reward: 366.57, Ewma Reward: 142.53\n",
      "Reward: 8.43, Ewma Reward: 141.19\n",
      "Reward: 422.91, Ewma Reward: 144.01\n",
      "Reward: 804.65, Ewma Reward: 150.61\n",
      "Reward: 815.24, Ewma Reward: 157.26\n",
      "Reward: 280.09, Ewma Reward: 158.49\n",
      "Reward: 1379.67, Ewma Reward: 170.70\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00018 |      -0.01425 |    1195.89209 |      1.23e-05 |       1.42477\n",
      "     -0.00029 |      -0.01426 |    1168.98901 |       0.00027 |       1.42594\n",
      "     -0.00052 |      -0.01427 |    1145.63452 |       0.00196 |       1.42680\n",
      "     -0.00073 |      -0.01427 |    1124.52991 |       0.00414 |       1.42686\n",
      "Evaluating losses...\n",
      "     -0.00093 |      -0.01426 |    1112.20178 |       0.00396 |       1.42604\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 507           |\n",
      "| EpThisIter      | 20            |\n",
      "| EpisodesSoFar   | 40            |\n",
      "| TimeElapsed     | 13.7          |\n",
      "| TimestepsSoFar  | 16384         |\n",
      "| ev_tdlam_before | 0.00826       |\n",
      "| loss_ent        | 1.4260415     |\n",
      "| loss_kl         | 0.00395896    |\n",
      "| loss_pol_entpen | -0.014260414  |\n",
      "| loss_pol_surr   | -0.0009345133 |\n",
      "| loss_vf_loss    | 1112.2018     |\n",
      "-----------------------------------\n",
      "********** Iteration 2 ************\n",
      "Reward: 788.73, Ewma Reward: 176.88\n",
      "Reward: -349.89, Ewma Reward: 171.61\n",
      "Reward: 1068.97, Ewma Reward: 180.59\n",
      "Reward: -675.92, Ewma Reward: 172.02\n",
      "Reward: 924.30, Ewma Reward: 179.54\n",
      "Reward: -98.84, Ewma Reward: 176.76\n",
      "Reward: 930.13, Ewma Reward: 184.29\n",
      "Reward: 1422.31, Ewma Reward: 196.67\n",
      "Reward: -107.77, Ewma Reward: 193.63\n",
      "Reward: 1233.86, Ewma Reward: 204.03\n",
      "Reward: 1043.62, Ewma Reward: 212.43\n",
      "Reward: 50.68, Ewma Reward: 210.81\n",
      "Reward: 1055.93, Ewma Reward: 219.26\n",
      "Reward: -646.70, Ewma Reward: 210.60\n",
      "Reward: 1101.14, Ewma Reward: 219.51\n",
      "Reward: 636.23, Ewma Reward: 223.67\n",
      "Reward: 1019.18, Ewma Reward: 231.63\n",
      "Reward: 207.56, Ewma Reward: 231.39\n",
      "Reward: 460.71, Ewma Reward: 233.68\n",
      "Reward: 746.50, Ewma Reward: 238.81\n",
      "Reward: 792.80, Ewma Reward: 244.35\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     1.65e-05 |      -0.01426 |    1378.62891 |      2.61e-05 |       1.42572\n",
      "     -0.00038 |      -0.01426 |    1358.64307 |       0.00015 |       1.42596\n",
      "     -0.00086 |      -0.01427 |    1340.81873 |       0.00037 |       1.42738\n",
      "     -0.00118 |      -0.01429 |    1324.55762 |       0.00084 |       1.42945\n",
      "Evaluating losses...\n",
      "     -0.00130 |      -0.01431 |    1315.02161 |       0.00126 |       1.43109\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 523           |\n",
      "| EpThisIter      | 21            |\n",
      "| EpisodesSoFar   | 61            |\n",
      "| TimeElapsed     | 28.4          |\n",
      "| TimestepsSoFar  | 24576         |\n",
      "| ev_tdlam_before | 0.0202        |\n",
      "| loss_ent        | 1.431091      |\n",
      "| loss_kl         | 0.0012627576  |\n",
      "| loss_pol_entpen | -0.014310909  |\n",
      "| loss_pol_surr   | -0.0013002213 |\n",
      "| loss_vf_loss    | 1315.0216     |\n",
      "-----------------------------------\n",
      "********** Iteration 3 ************\n",
      "Reward: -221.41, Ewma Reward: 239.69\n",
      "Reward: 1338.71, Ewma Reward: 250.68\n",
      "Reward: 316.05, Ewma Reward: 251.34\n",
      "Reward: 1222.19, Ewma Reward: 261.05\n",
      "Reward: 1032.19, Ewma Reward: 268.76\n",
      "Reward: -137.24, Ewma Reward: 264.70\n",
      "Reward: -217.78, Ewma Reward: 259.87\n",
      "Reward: -1344.86, Ewma Reward: 243.82\n",
      "Reward: -1071.78, Ewma Reward: 230.67\n",
      "Reward: 707.73, Ewma Reward: 235.44\n",
      "Reward: 564.05, Ewma Reward: 238.73\n",
      "Reward: 107.50, Ewma Reward: 237.41\n",
      "Reward: 168.36, Ewma Reward: 236.72\n",
      "Reward: 761.42, Ewma Reward: 241.97\n",
      "Reward: 1159.31, Ewma Reward: 251.14\n",
      "Reward: 692.58, Ewma Reward: 255.56\n",
      "Reward: 252.97, Ewma Reward: 255.53\n",
      "Reward: 536.24, Ewma Reward: 258.34\n",
      "Reward: 582.17, Ewma Reward: 261.58\n",
      "Reward: 748.26, Ewma Reward: 266.44\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     2.60e-05 |      -0.01432 |    1125.02625 |      1.49e-05 |       1.43228\n",
      "     -0.00051 |      -0.01435 |    1110.89392 |       0.00084 |       1.43507\n",
      "     -0.00123 |      -0.01438 |    1094.31396 |       0.00338 |       1.43759\n",
      "     -0.00156 |      -0.01439 |    1075.36768 |       0.00413 |       1.43925\n",
      "Evaluating losses...\n",
      "     -0.00193 |      -0.01440 |    1062.82397 |       0.00245 |       1.44025\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 483           |\n",
      "| EpThisIter      | 20            |\n",
      "| EpisodesSoFar   | 81            |\n",
      "| TimeElapsed     | 49.4          |\n",
      "| TimestepsSoFar  | 32768         |\n",
      "| ev_tdlam_before | 0.0319        |\n",
      "| loss_ent        | 1.4402462     |\n",
      "| loss_kl         | 0.0024501774  |\n",
      "| loss_pol_entpen | -0.014402462  |\n",
      "| loss_pol_surr   | -0.0019275893 |\n",
      "| loss_vf_loss    | 1062.824      |\n",
      "-----------------------------------\n",
      "********** Iteration 4 ************\n",
      "Reward: -816.97, Ewma Reward: 255.61\n",
      "Reward: 583.98, Ewma Reward: 258.89\n",
      "Reward: 236.84, Ewma Reward: 258.67\n",
      "Reward: 807.64, Ewma Reward: 264.16\n",
      "Reward: 228.53, Ewma Reward: 263.81\n",
      "Reward: 1289.50, Ewma Reward: 274.06\n",
      "Reward: 187.48, Ewma Reward: 273.20\n",
      "Reward: 43.57, Ewma Reward: 270.90\n",
      "Reward: -186.85, Ewma Reward: 266.32\n",
      "Reward: 921.82, Ewma Reward: 272.88\n",
      "Reward: 158.10, Ewma Reward: 271.73\n",
      "Reward: 1009.61, Ewma Reward: 279.11\n",
      "Reward: 904.35, Ewma Reward: 285.36\n",
      "Reward: 784.66, Ewma Reward: 290.35\n",
      "Reward: 110.06, Ewma Reward: 288.55\n",
      "Reward: 505.72, Ewma Reward: 290.72\n",
      "Reward: -222.14, Ewma Reward: 285.59\n",
      "Reward: 628.88, Ewma Reward: 289.03\n",
      "Reward: 128.23, Ewma Reward: 287.42\n",
      "Reward: -1195.47, Ewma Reward: 272.59\n",
      "Reward: 55.16, Ewma Reward: 270.42\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00036 |      -0.01441 |     724.12451 |       0.00015 |       1.44060\n",
      "      0.00035 |      -0.01441 |     717.68787 |       0.00023 |       1.44058\n",
      "     1.64e-06 |      -0.01439 |     710.21228 |       0.00025 |       1.43929\n",
      "     -0.00074 |      -0.01437 |     702.41833 |       0.00199 |       1.43737\n",
      "Evaluating losses...\n",
      "     -0.00076 |      -0.01436 |     697.73730 |       0.00330 |       1.43628\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 440           |\n",
      "| EpThisIter      | 21            |\n",
      "| EpisodesSoFar   | 102           |\n",
      "| TimeElapsed     | 65.2          |\n",
      "| TimestepsSoFar  | 40960         |\n",
      "| ev_tdlam_before | 0.0491        |\n",
      "| loss_ent        | 1.4362752     |\n",
      "| loss_kl         | 0.0033034878  |\n",
      "| loss_pol_entpen | -0.014362752  |\n",
      "| loss_pol_surr   | -0.0007560202 |\n",
      "| loss_vf_loss    | 697.7373      |\n",
      "-----------------------------------\n",
      "********** Iteration 5 ************\n",
      "Reward: 546.80, Ewma Reward: 273.18\n",
      "Reward: 1088.44, Ewma Reward: 281.33\n",
      "Reward: 69.04, Ewma Reward: 279.21\n",
      "Reward: 1236.19, Ewma Reward: 288.78\n",
      "Reward: 526.85, Ewma Reward: 291.16\n",
      "Reward: 209.49, Ewma Reward: 290.34\n",
      "Reward: 811.81, Ewma Reward: 295.56\n",
      "Reward: 382.35, Ewma Reward: 296.43\n",
      "Reward: 1528.05, Ewma Reward: 308.74\n",
      "Reward: 177.68, Ewma Reward: 307.43\n",
      "Reward: 680.90, Ewma Reward: 311.17\n",
      "Reward: 369.57, Ewma Reward: 311.75\n",
      "Reward: 755.58, Ewma Reward: 316.19\n",
      "Reward: 285.89, Ewma Reward: 315.89\n",
      "Reward: 525.30, Ewma Reward: 317.98\n",
      "Reward: 357.55, Ewma Reward: 318.38\n",
      "Reward: 781.61, Ewma Reward: 323.01\n",
      "Reward: 1049.93, Ewma Reward: 330.28\n",
      "Reward: 248.27, Ewma Reward: 329.46\n",
      "Reward: 785.03, Ewma Reward: 334.01\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00012 |      -0.01436 |     878.57422 |      3.12e-05 |       1.43577\n",
      "     5.38e-05 |      -0.01435 |     860.12646 |      3.33e-05 |       1.43505\n",
      "     -0.00015 |      -0.01435 |     841.35388 |      9.05e-05 |       1.43547\n",
      "     -0.00029 |      -0.01437 |     823.52930 |       0.00105 |       1.43661\n",
      "Evaluating losses...\n",
      "     -0.00063 |      -0.01437 |     812.77234 |       0.00237 |       1.43732\n",
      "------------------------------------\n",
      "| EpLenMean       | 400            |\n",
      "| EpRewMean       | 461            |\n",
      "| EpThisIter      | 20             |\n",
      "| EpisodesSoFar   | 122            |\n",
      "| TimeElapsed     | 70.2           |\n",
      "| TimestepsSoFar  | 49152          |\n",
      "| ev_tdlam_before | -0.00402       |\n",
      "| loss_ent        | 1.437322       |\n",
      "| loss_kl         | 0.0023745294   |\n",
      "| loss_pol_entpen | -0.01437322    |\n",
      "| loss_pol_surr   | -0.00063336734 |\n",
      "| loss_vf_loss    | 812.77234      |\n",
      "------------------------------------\n",
      "********** Iteration 6 ************\n",
      "Reward: 1238.75, Ewma Reward: 343.06\n",
      "Reward: 790.63, Ewma Reward: 347.54\n",
      "Reward: 405.78, Ewma Reward: 348.12\n",
      "Reward: 1102.70, Ewma Reward: 355.66\n",
      "Reward: 999.76, Ewma Reward: 362.11\n",
      "Reward: 1201.18, Ewma Reward: 370.50\n",
      "Reward: 587.77, Ewma Reward: 372.67\n",
      "Reward: 656.67, Ewma Reward: 375.51\n",
      "Reward: 61.47, Ewma Reward: 372.37\n",
      "Reward: 1561.38, Ewma Reward: 384.26\n",
      "Reward: 440.99, Ewma Reward: 384.83\n",
      "Reward: 42.66, Ewma Reward: 381.40\n",
      "Reward: -1333.79, Ewma Reward: 364.25\n",
      "Reward: 1317.26, Ewma Reward: 373.78\n",
      "Reward: -244.78, Ewma Reward: 367.60\n",
      "Reward: 708.50, Ewma Reward: 371.01\n",
      "Reward: -19.73, Ewma Reward: 367.10\n",
      "Reward: -125.27, Ewma Reward: 362.17\n",
      "Reward: 606.71, Ewma Reward: 364.62\n",
      "Reward: 293.77, Ewma Reward: 363.91\n",
      "Reward: 122.97, Ewma Reward: 361.50\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00015 |      -0.01438 |     992.28088 |       0.00013 |       1.43776\n",
      "     3.87e-07 |      -0.01439 |     979.25439 |       0.00040 |       1.43850\n",
      "     -0.00018 |      -0.01439 |     964.40704 |       0.00042 |       1.43869\n",
      "     -0.00019 |      -0.01439 |     950.35199 |       0.00069 |       1.43894\n",
      "Evaluating losses...\n",
      "     -0.00052 |      -0.01439 |     942.23242 |       0.00087 |       1.43907\n",
      "------------------------------------\n",
      "| EpLenMean       | 400            |\n",
      "| EpRewMean       | 463            |\n",
      "| EpThisIter      | 21             |\n",
      "| EpisodesSoFar   | 143            |\n",
      "| TimeElapsed     | 81.2           |\n",
      "| TimestepsSoFar  | 57344          |\n",
      "| ev_tdlam_before | 0.072          |\n",
      "| loss_ent        | 1.439066       |\n",
      "| loss_kl         | 0.0008708249   |\n",
      "| loss_pol_entpen | -0.01439066    |\n",
      "| loss_pol_surr   | -0.00051859627 |\n",
      "| loss_vf_loss    | 942.2324       |\n",
      "------------------------------------\n",
      "********** Iteration 7 ************\n",
      "Reward: 875.60, Ewma Reward: 366.64\n",
      "Reward: 683.60, Ewma Reward: 369.81\n",
      "Reward: 226.26, Ewma Reward: 368.38\n",
      "Reward: 338.78, Ewma Reward: 368.08\n",
      "Reward: 1521.59, Ewma Reward: 379.62\n",
      "Reward: -765.89, Ewma Reward: 368.16\n",
      "Reward: -2628.94, Ewma Reward: 338.19\n",
      "Reward: 84.44, Ewma Reward: 335.65\n",
      "Reward: 781.41, Ewma Reward: 340.11\n",
      "Reward: 484.51, Ewma Reward: 341.55\n",
      "Reward: 479.82, Ewma Reward: 342.94\n",
      "Reward: -355.72, Ewma Reward: 335.95\n",
      "Reward: 810.54, Ewma Reward: 340.70\n",
      "Reward: -168.11, Ewma Reward: 335.61\n",
      "Reward: 25.55, Ewma Reward: 332.51\n",
      "Reward: 1102.72, Ewma Reward: 340.21\n",
      "Reward: 573.92, Ewma Reward: 342.55\n",
      "Reward: 507.47, Ewma Reward: 344.20\n",
      "Reward: 574.18, Ewma Reward: 346.50\n",
      "Reward: 753.04, Ewma Reward: 350.56\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     2.62e-05 |      -0.01439 |    1843.93384 |      2.59e-06 |       1.43912\n",
      "     3.00e-05 |      -0.01439 |    1825.04089 |      1.16e-05 |       1.43887\n",
      "     -0.00011 |      -0.01438 |    1805.37012 |      1.58e-05 |       1.43812\n",
      "     -0.00035 |      -0.01437 |    1786.59058 |      5.93e-05 |       1.43742\n",
      "Evaluating losses...\n",
      "     -0.00049 |      -0.01437 |    1775.65625 |       0.00015 |       1.43699\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 410           |\n",
      "| EpThisIter      | 20            |\n",
      "| EpisodesSoFar   | 163           |\n",
      "| TimeElapsed     | 94.3          |\n",
      "| TimestepsSoFar  | 65536         |\n",
      "| ev_tdlam_before | 0.105         |\n",
      "| loss_ent        | 1.4369948     |\n",
      "| loss_kl         | 0.00015406992 |\n",
      "| loss_pol_entpen | -0.014369948  |\n",
      "| loss_pol_surr   | -0.0004867972 |\n",
      "| loss_vf_loss    | 1775.6562     |\n",
      "-----------------------------------\n",
      "********** Iteration 8 ************\n",
      "Reward: 910.84, Ewma Reward: 356.16\n",
      "Reward: 608.42, Ewma Reward: 358.69\n",
      "Reward: 1064.14, Ewma Reward: 365.74\n",
      "Reward: 445.71, Ewma Reward: 366.54\n",
      "Reward: -250.18, Ewma Reward: 360.37\n",
      "Reward: 444.75, Ewma Reward: 361.22\n",
      "Reward: 375.69, Ewma Reward: 361.36\n",
      "Reward: 313.62, Ewma Reward: 360.88\n",
      "Reward: 839.79, Ewma Reward: 365.67\n",
      "Reward: 241.50, Ewma Reward: 364.43\n",
      "Reward: 794.58, Ewma Reward: 368.73\n",
      "Reward: 414.88, Ewma Reward: 369.19\n",
      "Reward: 761.77, Ewma Reward: 373.12\n",
      "Reward: 1248.80, Ewma Reward: 381.88\n",
      "Reward: -782.97, Ewma Reward: 370.23\n",
      "Reward: 1090.91, Ewma Reward: 377.44\n",
      "Reward: -31.91, Ewma Reward: 373.34\n",
      "Reward: 579.83, Ewma Reward: 375.41\n",
      "Reward: -1275.23, Ewma Reward: 358.90\n",
      "Reward: 1367.49, Ewma Reward: 368.99\n",
      "Reward: 1184.73, Ewma Reward: 377.14\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     1.20e-05 |      -0.01437 |    1109.17529 |      5.89e-05 |       1.43682\n",
      "     -0.00023 |      -0.01437 |    1094.06714 |       0.00053 |       1.43698\n",
      "     -0.00065 |      -0.01438 |    1080.17236 |       0.00178 |       1.43794\n",
      "     -0.00058 |      -0.01439 |    1066.75952 |       0.00386 |       1.43892\n",
      "Evaluating losses...\n",
      "     -0.00084 |      -0.01439 |    1058.54248 |       0.00326 |       1.43905\n",
      "-----------------------------------\n",
      "| EpLenMean       | 400           |\n",
      "| EpRewMean       | 452           |\n",
      "| EpThisIter      | 21            |\n",
      "| EpisodesSoFar   | 184           |\n",
      "| TimeElapsed     | 108           |\n",
      "| TimestepsSoFar  | 73728         |\n",
      "| ev_tdlam_before | 0.212         |\n",
      "| loss_ent        | 1.4390458     |\n",
      "| loss_kl         | 0.0032567899  |\n",
      "| loss_pol_entpen | -0.014390457  |\n",
      "| loss_pol_surr   | -0.0008421028 |\n",
      "| loss_vf_loss    | 1058.5425     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo1.pposgd_simple.PPO1 at 0x7f7358ef4e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO1(MlpPolicy, env, verbose=1, schedule='constant', timesteps_per_actorbatch=8192, optim_batchsize=2048, gamma=0.99,tensorboard_log='./output/sb2/')\n",
    "model.learn(total_timesteps=160*410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sb2model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import network_sim\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History length: 10\n",
      "Features: ['sent latency inflation', 'latency ratio', 'send ratio']\n",
      "Getting min obs for ['sent latency inflation', 'latency ratio', 'send ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/envs/IL/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env=gym.make('PccNs-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/envs/IL/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model3=PPO(MlpPolicy,env,verbose=1 ,gamma=0.99,tensorboard_log='./output/sb3/',n_steps=8192,batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 258.64, Ewma Reward: 481.51\n",
      "Logging to ./output/sb3/PPO_5\n",
      "Reward: 493.88, Ewma Reward: 481.63\n",
      "Reward: 1145.87, Ewma Reward: 488.27\n",
      "Reward: 747.36, Ewma Reward: 490.86\n",
      "Reward: 120.23, Ewma Reward: 487.16\n",
      "Reward: 296.12, Ewma Reward: 485.25\n",
      "Reward: 780.72, Ewma Reward: 488.20\n",
      "Reward: 215.74, Ewma Reward: 485.48\n",
      "Reward: 18.80, Ewma Reward: 480.81\n",
      "Reward: 1014.43, Ewma Reward: 486.15\n",
      "Reward: 790.21, Ewma Reward: 489.19\n",
      "Reward: 275.12, Ewma Reward: 487.05\n",
      "Reward: 212.70, Ewma Reward: 484.30\n",
      "Reward: 760.36, Ewma Reward: 487.06\n",
      "Reward: -171.59, Ewma Reward: 480.48\n",
      "Reward: 239.80, Ewma Reward: 478.07\n",
      "Reward: 1249.04, Ewma Reward: 485.78\n",
      "Reward: 95.10, Ewma Reward: 481.87\n",
      "Reward: -375.56, Ewma Reward: 473.30\n",
      "Reward: -107.49, Ewma Reward: 467.49\n",
      "Reward: 469.16, Ewma Reward: 467.51\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 413      |\n",
      "| time/              |          |\n",
      "|    fps             | 1103     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "Reward: 456.12, Ewma Reward: 467.39\n",
      "Reward: 938.50, Ewma Reward: 472.11\n",
      "Reward: 24.27, Ewma Reward: 467.63\n",
      "Reward: -351.23, Ewma Reward: 459.44\n",
      "Reward: 956.41, Ewma Reward: 464.41\n",
      "Reward: 597.56, Ewma Reward: 465.74\n",
      "Reward: 431.81, Ewma Reward: 465.40\n",
      "Reward: 1412.68, Ewma Reward: 474.87\n",
      "Reward: 1201.06, Ewma Reward: 482.13\n",
      "Reward: 443.26, Ewma Reward: 481.75\n",
      "Reward: 262.65, Ewma Reward: 479.55\n",
      "Reward: 354.69, Ewma Reward: 478.31\n",
      "Reward: 623.66, Ewma Reward: 479.76\n",
      "Reward: 563.68, Ewma Reward: 480.60\n",
      "Reward: 1133.07, Ewma Reward: 487.12\n",
      "Reward: 645.17, Ewma Reward: 488.70\n",
      "Reward: 836.66, Ewma Reward: 492.18\n",
      "Reward: 1.86, Ewma Reward: 487.28\n",
      "Reward: 636.07, Ewma Reward: 488.77\n",
      "Reward: 564.56, Ewma Reward: 489.53\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 500          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 959          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031144184 |\n",
      "|    clip_fraction        | 0.00304      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00182      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000656    |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 550          |\n",
      "------------------------------------------\n",
      "Reward: 244.53, Ewma Reward: 487.08\n",
      "Reward: 97.85, Ewma Reward: 483.18\n",
      "Reward: 42.46, Ewma Reward: 478.78\n",
      "Reward: 1654.51, Ewma Reward: 490.53\n",
      "Reward: 336.80, Ewma Reward: 489.00\n",
      "Reward: 1113.52, Ewma Reward: 495.24\n",
      "Reward: 535.10, Ewma Reward: 495.64\n",
      "Reward: 477.26, Ewma Reward: 495.46\n",
      "Reward: 491.95, Ewma Reward: 495.42\n",
      "Reward: 405.75, Ewma Reward: 494.52\n",
      "Reward: 518.68, Ewma Reward: 494.77\n",
      "Reward: 1172.50, Ewma Reward: 501.54\n",
      "Reward: 991.39, Ewma Reward: 506.44\n",
      "Reward: -13.11, Ewma Reward: 501.25\n",
      "Reward: 671.90, Ewma Reward: 502.95\n",
      "Reward: -28.59, Ewma Reward: 497.64\n",
      "Reward: 1168.18, Ewma Reward: 504.34\n",
      "Reward: 139.37, Ewma Reward: 500.69\n",
      "Reward: 42.94, Ewma Reward: 496.12\n",
      "Reward: -33.35, Ewma Reward: 490.82\n",
      "Reward: 239.56, Ewma Reward: 488.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 496          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1081         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032459917 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.00191     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 354          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 745          |\n",
      "------------------------------------------\n",
      "Reward: 1320.83, Ewma Reward: 496.63\n",
      "Reward: 625.07, Ewma Reward: 497.92\n",
      "Reward: 1025.60, Ewma Reward: 503.20\n",
      "Reward: 160.80, Ewma Reward: 499.77\n",
      "Reward: 1176.72, Ewma Reward: 506.54\n",
      "Reward: 731.35, Ewma Reward: 508.79\n",
      "Reward: -173.84, Ewma Reward: 501.96\n",
      "Reward: 1078.30, Ewma Reward: 507.73\n",
      "Reward: 215.80, Ewma Reward: 504.81\n",
      "Reward: 301.40, Ewma Reward: 502.77\n",
      "Reward: 538.71, Ewma Reward: 503.13\n",
      "Reward: 76.57, Ewma Reward: 498.87\n",
      "Reward: 508.36, Ewma Reward: 498.96\n",
      "Reward: 615.66, Ewma Reward: 500.13\n",
      "Reward: 520.50, Ewma Reward: 500.33\n",
      "Reward: -64.98, Ewma Reward: 494.68\n",
      "Reward: -61.02, Ewma Reward: 489.12\n",
      "Reward: 379.71, Ewma Reward: 488.03\n",
      "Reward: 1119.62, Ewma Reward: 494.34\n",
      "Reward: 191.27, Ewma Reward: 491.31\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 501          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1080         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030151815 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.000213     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 351          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 738          |\n",
      "------------------------------------------\n",
      "Reward: 397.21, Ewma Reward: 490.37\n",
      "Reward: 994.58, Ewma Reward: 495.41\n",
      "Reward: 706.61, Ewma Reward: 497.53\n",
      "Reward: 1392.50, Ewma Reward: 506.48\n",
      "Reward: 930.49, Ewma Reward: 510.72\n",
      "Reward: 1224.36, Ewma Reward: 517.85\n",
      "Reward: 667.09, Ewma Reward: 519.34\n",
      "Reward: 864.19, Ewma Reward: 522.79\n",
      "Reward: -300.83, Ewma Reward: 514.56\n",
      "Reward: 1121.14, Ewma Reward: 520.62\n",
      "Reward: 28.35, Ewma Reward: 515.70\n",
      "Reward: 520.29, Ewma Reward: 515.75\n",
      "Reward: -66.84, Ewma Reward: 509.92\n",
      "Reward: -1542.35, Ewma Reward: 489.40\n",
      "Reward: 106.37, Ewma Reward: 485.57\n",
      "Reward: -804.01, Ewma Reward: 472.67\n",
      "Reward: 151.49, Ewma Reward: 469.46\n",
      "Reward: 975.05, Ewma Reward: 474.52\n",
      "Reward: 268.97, Ewma Reward: 472.46\n",
      "Reward: 131.43, Ewma Reward: 469.05\n",
      "Reward: -536.87, Ewma Reward: 458.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 461          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 961          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030065032 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.000372     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 291          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00036     |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 604          |\n",
      "------------------------------------------\n",
      "Reward: 412.57, Ewma Reward: 458.53\n",
      "Reward: 291.90, Ewma Reward: 456.86\n",
      "Reward: 969.46, Ewma Reward: 461.99\n",
      "Reward: 800.81, Ewma Reward: 465.37\n",
      "Reward: 613.18, Ewma Reward: 466.85\n",
      "Reward: 1281.83, Ewma Reward: 475.00\n",
      "Reward: -1600.02, Ewma Reward: 454.25\n",
      "Reward: 135.00, Ewma Reward: 451.06\n",
      "Reward: 1213.22, Ewma Reward: 458.68\n",
      "Reward: -75.05, Ewma Reward: 453.34\n",
      "Reward: 279.56, Ewma Reward: 451.61\n",
      "Reward: 358.28, Ewma Reward: 450.67\n",
      "Reward: 1287.80, Ewma Reward: 459.04\n",
      "Reward: 432.90, Ewma Reward: 458.78\n",
      "Reward: 1184.59, Ewma Reward: 466.04\n",
      "Reward: -204.54, Ewma Reward: 459.33\n",
      "Reward: 329.78, Ewma Reward: 458.04\n",
      "Reward: 1008.29, Ewma Reward: 463.54\n",
      "Reward: 721.85, Ewma Reward: 466.12\n",
      "Reward: 749.47, Ewma Reward: 468.96\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 483          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 962          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013505493 |\n",
      "|    clip_fraction        | 0.000317     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00297      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 562          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000231    |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 1.14e+03     |\n",
      "------------------------------------------\n",
      "Reward: 639.50, Ewma Reward: 470.66\n",
      "Reward: 180.28, Ewma Reward: 467.76\n",
      "Reward: 363.20, Ewma Reward: 466.71\n",
      "Reward: 23.99, Ewma Reward: 462.29\n",
      "Reward: 536.79, Ewma Reward: 463.03\n",
      "Reward: 421.63, Ewma Reward: 462.62\n",
      "Reward: 1420.95, Ewma Reward: 472.20\n",
      "Reward: 612.31, Ewma Reward: 473.60\n",
      "Reward: 1080.45, Ewma Reward: 479.67\n",
      "Reward: -156.30, Ewma Reward: 473.31\n",
      "Reward: 229.04, Ewma Reward: 470.87\n",
      "Reward: 1344.61, Ewma Reward: 479.61\n",
      "Reward: 1234.57, Ewma Reward: 487.16\n",
      "Reward: 467.39, Ewma Reward: 486.96\n",
      "Reward: 1044.35, Ewma Reward: 492.53\n",
      "Reward: 972.01, Ewma Reward: 497.33\n",
      "Reward: -21.94, Ewma Reward: 492.13\n",
      "Reward: 1188.86, Ewma Reward: 499.10\n",
      "Reward: 1299.33, Ewma Reward: 507.10\n",
      "Reward: 639.19, Ewma Reward: 508.42\n",
      "Reward: 167.50, Ewma Reward: 505.01\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 513           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 975           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 58            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036138928 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.4          |\n",
      "|    explained_variance   | 0.0961        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 608           |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000222     |\n",
      "|    std                  | 0.978         |\n",
      "|    value_loss           | 1.27e+03      |\n",
      "-------------------------------------------\n",
      "Reward: 1332.54, Ewma Reward: 513.29\n",
      "Reward: 959.58, Ewma Reward: 517.75\n",
      "Reward: 109.86, Ewma Reward: 513.67\n",
      "Reward: -920.33, Ewma Reward: 499.33\n",
      "Reward: 1233.28, Ewma Reward: 506.67\n",
      "Reward: 229.30, Ewma Reward: 503.90\n",
      "Reward: 640.80, Ewma Reward: 505.27\n",
      "Reward: 1057.40, Ewma Reward: 510.79\n",
      "Reward: 318.93, Ewma Reward: 508.87\n",
      "Reward: 494.21, Ewma Reward: 508.72\n",
      "Reward: 381.21, Ewma Reward: 507.45\n",
      "Reward: -1303.95, Ewma Reward: 489.34\n",
      "Reward: 829.98, Ewma Reward: 492.74\n",
      "Reward: -38.55, Ewma Reward: 487.43\n",
      "Reward: 932.91, Ewma Reward: 491.88\n",
      "Reward: 777.67, Ewma Reward: 494.74\n",
      "Reward: 1264.74, Ewma Reward: 502.44\n",
      "Reward: 979.04, Ewma Reward: 507.21\n",
      "Reward: -216.79, Ewma Reward: 499.97\n",
      "Reward: 574.08, Ewma Reward: 500.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 491          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 975          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012925944 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0623       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 519          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000249    |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "Reward: 802.36, Ewma Reward: 503.73\n",
      "Reward: 130.46, Ewma Reward: 499.99\n",
      "Reward: 102.76, Ewma Reward: 496.02\n",
      "Reward: 196.71, Ewma Reward: 493.03\n",
      "Reward: 907.53, Ewma Reward: 497.17\n",
      "Reward: 1560.62, Ewma Reward: 507.81\n",
      "Reward: 213.20, Ewma Reward: 504.86\n",
      "Reward: -34.01, Ewma Reward: 499.47\n",
      "Reward: 1379.45, Ewma Reward: 508.27\n",
      "Reward: 130.51, Ewma Reward: 504.49\n",
      "Reward: 261.21, Ewma Reward: 502.06\n",
      "Reward: 268.68, Ewma Reward: 499.73\n",
      "Reward: -128.37, Ewma Reward: 493.45\n",
      "Reward: 516.15, Ewma Reward: 493.67\n",
      "Reward: 208.77, Ewma Reward: 490.82\n",
      "Reward: 1033.08, Ewma Reward: 496.25\n",
      "Reward: 582.23, Ewma Reward: 497.11\n",
      "Reward: 318.96, Ewma Reward: 495.33\n",
      "Reward: 638.15, Ewma Reward: 496.75\n",
      "Reward: 1657.93, Ewma Reward: 508.37\n",
      "Reward: 911.11, Ewma Reward: 512.39\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 503          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1017         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024244303 |\n",
      "|    clip_fraction        | 0.00636      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 807          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Reward: 1053.99, Ewma Reward: 517.81\n",
      "Reward: 273.97, Ewma Reward: 515.37\n",
      "Reward: 169.68, Ewma Reward: 511.91\n",
      "Reward: 62.50, Ewma Reward: 507.42\n",
      "Reward: 9.76, Ewma Reward: 502.44\n",
      "Reward: -254.71, Ewma Reward: 494.87\n",
      "Reward: 1309.99, Ewma Reward: 503.02\n",
      "Reward: 221.52, Ewma Reward: 500.21\n",
      "Reward: 1048.67, Ewma Reward: 505.69\n",
      "Reward: 1143.60, Ewma Reward: 512.07\n",
      "Reward: 862.00, Ewma Reward: 515.57\n",
      "Reward: 57.41, Ewma Reward: 510.99\n",
      "Reward: 547.40, Ewma Reward: 511.35\n",
      "Reward: -91.04, Ewma Reward: 505.33\n",
      "Reward: -506.07, Ewma Reward: 495.21\n",
      "Reward: 852.35, Ewma Reward: 498.79\n",
      "Reward: 782.12, Ewma Reward: 501.62\n",
      "Reward: 1529.87, Ewma Reward: 511.90\n",
      "Reward: 673.53, Ewma Reward: 513.52\n",
      "Reward: 89.39, Ewma Reward: 509.28\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 543         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1008        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002745227 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.00195     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00061    |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 814         |\n",
      "-----------------------------------------\n",
      "Reward: 518.53, Ewma Reward: 509.37\n",
      "Reward: 180.23, Ewma Reward: 506.08\n",
      "Reward: 1221.55, Ewma Reward: 513.23\n",
      "Reward: 1012.09, Ewma Reward: 518.22\n",
      "Reward: 318.92, Ewma Reward: 516.23\n",
      "Reward: 1061.31, Ewma Reward: 521.68\n",
      "Reward: 770.07, Ewma Reward: 524.16\n",
      "Reward: 727.33, Ewma Reward: 526.19\n",
      "Reward: -162.50, Ewma Reward: 519.31\n",
      "Reward: 144.19, Ewma Reward: 515.56\n",
      "Reward: 229.32, Ewma Reward: 512.69\n",
      "Reward: 48.62, Ewma Reward: 508.05\n",
      "Reward: 327.17, Ewma Reward: 506.24\n",
      "Reward: 703.33, Ewma Reward: 508.22\n",
      "Reward: -180.88, Ewma Reward: 501.32\n",
      "Reward: 47.52, Ewma Reward: 496.79\n",
      "Reward: -32.97, Ewma Reward: 491.49\n",
      "Reward: 3.95, Ewma Reward: 486.61\n",
      "Reward: 661.69, Ewma Reward: 488.36\n",
      "Reward: 1227.21, Ewma Reward: 495.75\n",
      "Reward: 309.69, Ewma Reward: 493.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 528          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1021         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015869591 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0905       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 442          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000834    |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 902          |\n",
      "------------------------------------------\n",
      "Reward: 802.19, Ewma Reward: 496.98\n",
      "Reward: 509.65, Ewma Reward: 497.10\n",
      "Reward: 139.07, Ewma Reward: 493.52\n",
      "Reward: 812.51, Ewma Reward: 496.71\n",
      "Reward: 933.14, Ewma Reward: 501.08\n",
      "Reward: -123.72, Ewma Reward: 494.83\n",
      "Reward: 598.10, Ewma Reward: 495.86\n",
      "Reward: 786.49, Ewma Reward: 498.77\n",
      "Reward: 1328.63, Ewma Reward: 507.07\n",
      "Reward: -156.73, Ewma Reward: 500.43\n",
      "Reward: 659.56, Ewma Reward: 502.02\n",
      "Reward: 810.89, Ewma Reward: 505.11\n",
      "Reward: 283.25, Ewma Reward: 502.89\n",
      "Reward: 217.42, Ewma Reward: 500.03\n",
      "Reward: 48.93, Ewma Reward: 495.52\n",
      "Reward: 1060.97, Ewma Reward: 501.18\n",
      "Reward: 817.13, Ewma Reward: 504.34\n",
      "Reward: 915.61, Ewma Reward: 508.45\n",
      "Reward: 70.36, Ewma Reward: 504.07\n",
      "Reward: 163.40, Ewma Reward: 500.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 487          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1025         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022133826 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.000666    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000331    |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 542          |\n",
      "------------------------------------------\n",
      "Reward: 739.73, Ewma Reward: 503.05\n",
      "Reward: 1239.86, Ewma Reward: 510.42\n",
      "Reward: 1274.11, Ewma Reward: 518.06\n",
      "Reward: 829.22, Ewma Reward: 521.17\n",
      "Reward: 978.83, Ewma Reward: 525.75\n",
      "Reward: -244.12, Ewma Reward: 518.05\n",
      "Reward: 164.25, Ewma Reward: 514.51\n",
      "Reward: 683.75, Ewma Reward: 516.20\n",
      "Reward: 997.87, Ewma Reward: 521.02\n",
      "Reward: 857.10, Ewma Reward: 524.38\n",
      "Reward: -325.72, Ewma Reward: 515.88\n",
      "Reward: 894.92, Ewma Reward: 519.67\n",
      "Reward: 160.29, Ewma Reward: 516.08\n",
      "Reward: 234.22, Ewma Reward: 513.26\n",
      "Reward: 460.27, Ewma Reward: 512.73\n",
      "Reward: 201.82, Ewma Reward: 509.62\n",
      "Reward: -696.89, Ewma Reward: 497.55\n",
      "Reward: 1508.90, Ewma Reward: 507.67\n",
      "Reward: 1230.40, Ewma Reward: 514.89\n",
      "Reward: 195.60, Ewma Reward: 511.70\n",
      "Reward: 997.10, Ewma Reward: 516.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 527          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1013         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010148215 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.000649    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 309          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -6.8e-05     |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 630          |\n",
      "------------------------------------------\n",
      "Reward: 754.37, Ewma Reward: 518.93\n",
      "Reward: 1348.95, Ewma Reward: 527.23\n",
      "Reward: 780.57, Ewma Reward: 529.77\n",
      "Reward: 1103.23, Ewma Reward: 535.50\n",
      "Reward: 1136.54, Ewma Reward: 541.51\n",
      "Reward: 907.50, Ewma Reward: 545.17\n",
      "Reward: 119.66, Ewma Reward: 540.92\n",
      "Reward: 370.95, Ewma Reward: 539.22\n",
      "Reward: 510.18, Ewma Reward: 538.93\n",
      "Reward: 489.24, Ewma Reward: 538.43\n",
      "Reward: -51.39, Ewma Reward: 532.53\n",
      "Reward: 1063.99, Ewma Reward: 537.85\n",
      "Reward: 1182.44, Ewma Reward: 544.29\n",
      "Reward: 1049.75, Ewma Reward: 549.35\n",
      "Reward: 695.98, Ewma Reward: 550.81\n",
      "Reward: 564.36, Ewma Reward: 550.95\n",
      "Reward: 412.93, Ewma Reward: 549.57\n",
      "Reward: -7.91, Ewma Reward: 543.99\n",
      "Reward: 1224.20, Ewma Reward: 550.80\n",
      "Reward: 1515.01, Ewma Reward: 560.44\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 559           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1012          |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 113           |\n",
      "|    total_timesteps      | 114688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046974808 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 0.0949        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 571           |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000308     |\n",
      "|    std                  | 0.973         |\n",
      "|    value_loss           | 1.12e+03      |\n",
      "-------------------------------------------\n",
      "Reward: 893.73, Ewma Reward: 563.77\n",
      "Reward: 560.56, Ewma Reward: 563.74\n",
      "Reward: 112.75, Ewma Reward: 559.23\n",
      "Reward: 1081.57, Ewma Reward: 564.45\n",
      "Reward: 228.96, Ewma Reward: 561.10\n",
      "Reward: 275.19, Ewma Reward: 558.24\n",
      "Reward: 209.96, Ewma Reward: 554.75\n",
      "Reward: -243.57, Ewma Reward: 546.77\n",
      "Reward: 429.17, Ewma Reward: 545.60\n",
      "Reward: 383.48, Ewma Reward: 543.97\n",
      "Reward: 1074.66, Ewma Reward: 549.28\n",
      "Reward: 1093.08, Ewma Reward: 554.72\n",
      "Reward: 1399.79, Ewma Reward: 563.17\n",
      "Reward: 91.37, Ewma Reward: 558.45\n",
      "Reward: 858.62, Ewma Reward: 561.45\n",
      "Reward: 1224.83, Ewma Reward: 568.09\n",
      "Reward: 242.95, Ewma Reward: 564.84\n",
      "Reward: 157.50, Ewma Reward: 560.76\n",
      "Reward: 200.97, Ewma Reward: 557.16\n",
      "Reward: 1003.53, Ewma Reward: 561.63\n",
      "Reward: 634.23, Ewma Reward: 562.35\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 574          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 998          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033992052 |\n",
      "|    clip_fraction        | 0.00858      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00211      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 523          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0007      |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 1.06e+03     |\n",
      "------------------------------------------\n",
      "Reward: 363.15, Ewma Reward: 560.36\n",
      "Reward: -197.82, Ewma Reward: 552.78\n",
      "Reward: 495.52, Ewma Reward: 552.21\n",
      "Reward: 31.64, Ewma Reward: 547.00\n",
      "Reward: 707.18, Ewma Reward: 548.60\n",
      "Reward: 46.78, Ewma Reward: 543.59\n",
      "Reward: 839.15, Ewma Reward: 546.54\n",
      "Reward: 1316.13, Ewma Reward: 554.24\n",
      "Reward: 1033.68, Ewma Reward: 559.03\n",
      "Reward: -139.93, Ewma Reward: 552.04\n",
      "Reward: 940.10, Ewma Reward: 555.92\n",
      "Reward: 292.12, Ewma Reward: 553.28\n",
      "Reward: 1010.32, Ewma Reward: 557.86\n",
      "Reward: 906.77, Ewma Reward: 561.34\n",
      "Reward: 248.33, Ewma Reward: 558.21\n",
      "Reward: 930.53, Ewma Reward: 561.94\n",
      "Reward: 474.62, Ewma Reward: 561.06\n",
      "Reward: 781.79, Ewma Reward: 563.27\n",
      "Reward: 396.88, Ewma Reward: 561.61\n",
      "Reward: 373.58, Ewma Reward: 559.73\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 597          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 996          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021627313 |\n",
      "|    clip_fraction        | 0.00154      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.000406     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 367          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000286    |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 728          |\n",
      "------------------------------------------\n",
      "Reward: -188.43, Ewma Reward: 552.25\n",
      "Reward: 802.20, Ewma Reward: 554.75\n",
      "Reward: 681.85, Ewma Reward: 556.02\n",
      "Reward: 679.12, Ewma Reward: 557.25\n",
      "Reward: 881.47, Ewma Reward: 560.49\n",
      "Reward: 478.50, Ewma Reward: 559.67\n",
      "Reward: -58.34, Ewma Reward: 553.49\n",
      "Reward: 486.60, Ewma Reward: 552.82\n",
      "Reward: 603.27, Ewma Reward: 553.33\n",
      "Reward: 851.41, Ewma Reward: 556.31\n",
      "Reward: 767.72, Ewma Reward: 558.42\n",
      "Reward: 771.29, Ewma Reward: 560.55\n",
      "Reward: -13.61, Ewma Reward: 554.81\n",
      "Reward: 390.10, Ewma Reward: 553.16\n",
      "Reward: 574.88, Ewma Reward: 553.38\n",
      "Reward: 563.36, Ewma Reward: 553.48\n",
      "Reward: -517.72, Ewma Reward: 542.77\n",
      "Reward: 1002.60, Ewma Reward: 547.36\n",
      "Reward: 438.05, Ewma Reward: 546.27\n",
      "Reward: 840.01, Ewma Reward: 549.21\n",
      "Reward: 676.69, Ewma Reward: 550.48\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 578          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 985          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020274767 |\n",
      "|    clip_fraction        | 0.00814      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00138      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 306          |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000667    |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 641          |\n",
      "------------------------------------------\n",
      "Reward: 631.66, Ewma Reward: 551.29\n",
      "Reward: 950.13, Ewma Reward: 555.28\n",
      "Reward: -9.86, Ewma Reward: 549.63\n",
      "Reward: -247.39, Ewma Reward: 541.66\n",
      "Reward: 805.42, Ewma Reward: 544.30\n",
      "Reward: 1092.42, Ewma Reward: 549.78\n",
      "Reward: 753.86, Ewma Reward: 551.82\n",
      "Reward: 123.47, Ewma Reward: 547.54\n",
      "Reward: 1481.10, Ewma Reward: 556.87\n",
      "Reward: 15.53, Ewma Reward: 551.46\n",
      "Reward: 486.68, Ewma Reward: 550.81\n",
      "Reward: 618.51, Ewma Reward: 551.49\n",
      "Reward: -357.84, Ewma Reward: 542.40\n",
      "Reward: 287.32, Ewma Reward: 539.84\n",
      "Reward: 77.59, Ewma Reward: 535.22\n",
      "Reward: -433.04, Ewma Reward: 525.54\n",
      "Reward: 713.19, Ewma Reward: 527.42\n",
      "Reward: 1185.13, Ewma Reward: 533.99\n",
      "Reward: 98.11, Ewma Reward: 529.63\n",
      "Reward: 520.69, Ewma Reward: 529.55\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 553          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 972          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019380063 |\n",
      "|    clip_fraction        | 0.00848      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 7.41e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 290          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000666    |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 593          |\n",
      "------------------------------------------\n",
      "Reward: 1320.88, Ewma Reward: 537.46\n",
      "Reward: -75.26, Ewma Reward: 531.33\n",
      "Reward: 1117.89, Ewma Reward: 537.20\n",
      "Reward: 1445.33, Ewma Reward: 546.28\n",
      "Reward: 611.79, Ewma Reward: 546.93\n",
      "Reward: 1130.37, Ewma Reward: 552.77\n",
      "Reward: 386.04, Ewma Reward: 551.10\n",
      "Reward: -79.57, Ewma Reward: 544.79\n",
      "Reward: 1039.44, Ewma Reward: 549.74\n",
      "Reward: 709.23, Ewma Reward: 551.34\n",
      "Reward: 732.80, Ewma Reward: 553.15\n",
      "Reward: 1253.09, Ewma Reward: 560.15\n",
      "Reward: 105.39, Ewma Reward: 555.60\n",
      "Reward: 1076.75, Ewma Reward: 560.81\n",
      "Reward: 182.12, Ewma Reward: 557.03\n",
      "Reward: 1364.45, Ewma Reward: 565.10\n",
      "Reward: 932.53, Ewma Reward: 568.77\n",
      "Reward: 924.27, Ewma Reward: 572.33\n",
      "Reward: 1324.86, Ewma Reward: 579.86\n",
      "Reward: 956.49, Ewma Reward: 583.62\n",
      "Reward: 908.85, Ewma Reward: 586.87\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 581         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 968         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002521988 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00571     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 389         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 788         |\n",
      "-----------------------------------------\n",
      "Reward: 587.17, Ewma Reward: 586.88\n",
      "Reward: -46.70, Ewma Reward: 580.54\n",
      "Reward: -495.91, Ewma Reward: 569.78\n",
      "Reward: -47.18, Ewma Reward: 563.61\n",
      "Reward: 219.46, Ewma Reward: 560.17\n",
      "Reward: 284.89, Ewma Reward: 557.41\n",
      "Reward: 182.20, Ewma Reward: 553.66\n",
      "Reward: -594.52, Ewma Reward: 542.18\n",
      "Reward: -55.61, Ewma Reward: 536.20\n",
      "Reward: 779.12, Ewma Reward: 538.63\n",
      "Reward: 435.10, Ewma Reward: 537.59\n",
      "Reward: -70.76, Ewma Reward: 531.51\n",
      "Reward: 1292.89, Ewma Reward: 539.12\n",
      "Reward: -263.39, Ewma Reward: 531.10\n",
      "Reward: 44.23, Ewma Reward: 526.23\n",
      "Reward: 489.40, Ewma Reward: 525.86\n",
      "Reward: 436.82, Ewma Reward: 524.97\n",
      "Reward: -21.15, Ewma Reward: 519.51\n",
      "Reward: 607.59, Ewma Reward: 520.39\n",
      "Reward: 309.89, Ewma Reward: 518.29\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 516          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 957          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036666892 |\n",
      "|    clip_fraction        | 0.0071       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.000542     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 589          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000756    |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.16e+03     |\n",
      "------------------------------------------\n",
      "Reward: 441.27, Ewma Reward: 517.52\n",
      "Reward: 1189.94, Ewma Reward: 524.24\n",
      "Reward: 34.74, Ewma Reward: 519.35\n",
      "Reward: 1136.24, Ewma Reward: 525.51\n",
      "Reward: -69.38, Ewma Reward: 519.57\n",
      "Reward: 996.40, Ewma Reward: 524.33\n",
      "Reward: 736.42, Ewma Reward: 526.45\n",
      "Reward: 316.73, Ewma Reward: 524.36\n",
      "Reward: 1048.66, Ewma Reward: 529.60\n",
      "Reward: 1102.87, Ewma Reward: 535.33\n",
      "Reward: -119.01, Ewma Reward: 528.79\n",
      "Reward: -163.39, Ewma Reward: 521.87\n",
      "Reward: 242.02, Ewma Reward: 519.07\n",
      "Reward: 747.95, Ewma Reward: 521.36\n",
      "Reward: 1347.41, Ewma Reward: 529.62\n",
      "Reward: -136.80, Ewma Reward: 522.95\n",
      "Reward: 1043.51, Ewma Reward: 528.16\n",
      "Reward: 1172.21, Ewma Reward: 534.60\n",
      "Reward: 271.47, Ewma Reward: 531.97\n",
      "Reward: 415.85, Ewma Reward: 530.81\n",
      "Reward: 295.54, Ewma Reward: 528.46\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 517          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 951          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014115176 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 391          |\n",
      "------------------------------------------\n",
      "Reward: 950.60, Ewma Reward: 532.68\n",
      "Reward: 1079.08, Ewma Reward: 538.14\n",
      "Reward: 478.37, Ewma Reward: 537.54\n",
      "Reward: -31.30, Ewma Reward: 531.85\n",
      "Reward: 537.50, Ewma Reward: 531.91\n",
      "Reward: 1244.68, Ewma Reward: 539.04\n",
      "Reward: 903.11, Ewma Reward: 542.68\n",
      "Reward: -130.52, Ewma Reward: 535.95\n",
      "Reward: 1345.97, Ewma Reward: 544.05\n",
      "Reward: 364.98, Ewma Reward: 542.26\n",
      "Reward: 1142.73, Ewma Reward: 548.26\n",
      "Reward: 1293.89, Ewma Reward: 555.72\n",
      "Reward: 462.87, Ewma Reward: 554.79\n",
      "Reward: 857.23, Ewma Reward: 557.81\n",
      "Reward: 1298.53, Ewma Reward: 565.22\n",
      "Reward: 882.93, Ewma Reward: 568.40\n",
      "Reward: 797.85, Ewma Reward: 570.69\n",
      "Reward: 954.40, Ewma Reward: 574.53\n",
      "Reward: 462.33, Ewma Reward: 573.41\n",
      "Reward: 706.98, Ewma Reward: 574.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 563          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 950          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024300027 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0296       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 392          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000901    |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 822          |\n",
      "------------------------------------------\n",
      "Reward: 213.31, Ewma Reward: 571.13\n",
      "Reward: 376.69, Ewma Reward: 569.19\n",
      "Reward: 772.55, Ewma Reward: 571.22\n",
      "Reward: 481.54, Ewma Reward: 570.32\n",
      "Reward: 556.15, Ewma Reward: 570.18\n",
      "Reward: 1279.62, Ewma Reward: 577.27\n",
      "Reward: 429.09, Ewma Reward: 575.79\n",
      "Reward: 887.78, Ewma Reward: 578.91\n",
      "Reward: 511.05, Ewma Reward: 578.23\n",
      "Reward: 523.40, Ewma Reward: 577.69\n",
      "Reward: 280.83, Ewma Reward: 574.72\n",
      "Reward: 1037.54, Ewma Reward: 579.35\n",
      "Reward: 867.33, Ewma Reward: 582.23\n",
      "Reward: 208.76, Ewma Reward: 578.49\n",
      "Reward: 1072.83, Ewma Reward: 583.43\n",
      "Reward: 992.38, Ewma Reward: 587.52\n",
      "Reward: 1094.86, Ewma Reward: 592.60\n",
      "Reward: 1082.27, Ewma Reward: 597.49\n",
      "Reward: 622.84, Ewma Reward: 597.75\n",
      "Reward: 479.58, Ewma Reward: 596.57\n",
      "Reward: 424.28, Ewma Reward: 594.84\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 609           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 942           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 199           |\n",
      "|    total_timesteps      | 188416        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9943337e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.4          |\n",
      "|    explained_variance   | 0.0112        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 476           |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -9.96e-05     |\n",
      "|    std                  | 0.978         |\n",
      "|    value_loss           | 968           |\n",
      "-------------------------------------------\n",
      "Reward: 495.00, Ewma Reward: 593.84\n",
      "Reward: 996.94, Ewma Reward: 597.87\n",
      "Reward: 302.93, Ewma Reward: 594.93\n",
      "Reward: 539.23, Ewma Reward: 594.37\n",
      "Reward: 149.32, Ewma Reward: 589.92\n",
      "Reward: 1000.07, Ewma Reward: 594.02\n",
      "Reward: 1287.12, Ewma Reward: 600.95\n",
      "Reward: 151.77, Ewma Reward: 596.46\n",
      "Reward: 1021.30, Ewma Reward: 600.71\n",
      "Reward: -60.43, Ewma Reward: 594.10\n",
      "Reward: 1363.24, Ewma Reward: 601.79\n",
      "Reward: 510.84, Ewma Reward: 600.88\n",
      "Reward: 183.59, Ewma Reward: 596.70\n",
      "Reward: 382.59, Ewma Reward: 594.56\n",
      "Reward: 466.60, Ewma Reward: 593.28\n",
      "Reward: 829.60, Ewma Reward: 595.65\n",
      "Reward: 1387.60, Ewma Reward: 603.57\n",
      "Reward: 932.84, Ewma Reward: 606.86\n",
      "Reward: 753.42, Ewma Reward: 608.33\n",
      "Reward: 1045.75, Ewma Reward: 612.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 591          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 936          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032816522 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.00081     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 354          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000574    |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 693          |\n",
      "------------------------------------------\n",
      "Reward: -97.12, Ewma Reward: 605.60\n",
      "Reward: 67.20, Ewma Reward: 600.22\n",
      "Reward: 533.48, Ewma Reward: 599.55\n",
      "Reward: 1009.44, Ewma Reward: 603.65\n",
      "Reward: 1114.21, Ewma Reward: 608.75\n",
      "Reward: 899.87, Ewma Reward: 611.67\n",
      "Reward: 1087.60, Ewma Reward: 616.42\n",
      "Reward: 670.59, Ewma Reward: 616.97\n",
      "Reward: 1291.98, Ewma Reward: 623.72\n",
      "Reward: 736.77, Ewma Reward: 624.85\n",
      "Reward: 1034.48, Ewma Reward: 628.94\n",
      "Reward: 1006.70, Ewma Reward: 632.72\n",
      "Reward: 775.75, Ewma Reward: 634.15\n",
      "Reward: 1044.89, Ewma Reward: 638.26\n",
      "Reward: 909.83, Ewma Reward: 640.97\n",
      "Reward: 1211.96, Ewma Reward: 646.68\n",
      "Reward: 267.46, Ewma Reward: 642.89\n",
      "Reward: 983.08, Ewma Reward: 646.29\n",
      "Reward: 1236.35, Ewma Reward: 652.19\n",
      "Reward: 312.81, Ewma Reward: 648.80\n",
      "Reward: 1273.75, Ewma Reward: 655.05\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 713          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 928          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015727087 |\n",
      "|    clip_fraction        | 0.000525     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 5.05e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 433          |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000273    |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 866          |\n",
      "------------------------------------------\n",
      "Reward: 450.72, Ewma Reward: 653.01\n",
      "Reward: 500.76, Ewma Reward: 651.48\n",
      "Reward: 446.26, Ewma Reward: 649.43\n",
      "Reward: 861.15, Ewma Reward: 651.55\n",
      "Reward: 101.91, Ewma Reward: 646.05\n",
      "Reward: 895.03, Ewma Reward: 648.54\n",
      "Reward: 247.96, Ewma Reward: 644.54\n",
      "Reward: 185.06, Ewma Reward: 639.94\n",
      "Reward: 103.29, Ewma Reward: 634.58\n",
      "Reward: 509.03, Ewma Reward: 633.32\n",
      "Reward: 288.06, Ewma Reward: 629.87\n",
      "Reward: 807.05, Ewma Reward: 631.64\n",
      "Reward: 1324.75, Ewma Reward: 638.57\n",
      "Reward: -583.57, Ewma Reward: 626.35\n",
      "Reward: 25.99, Ewma Reward: 620.35\n",
      "Reward: -66.98, Ewma Reward: 613.47\n",
      "Reward: 1103.01, Ewma Reward: 618.37\n",
      "Reward: 512.99, Ewma Reward: 617.31\n",
      "Reward: -145.52, Ewma Reward: 609.69\n",
      "Reward: 237.74, Ewma Reward: 605.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 926          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 229          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021287375 |\n",
      "|    clip_fraction        | 0.000281     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0135       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 551          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000321    |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "Reward: 801.85, Ewma Reward: 607.92\n",
      "Reward: 363.26, Ewma Reward: 605.48\n",
      "Reward: 114.98, Ewma Reward: 600.57\n",
      "Reward: 418.74, Ewma Reward: 598.75\n",
      "Reward: 848.44, Ewma Reward: 601.25\n",
      "Reward: 849.46, Ewma Reward: 603.73\n",
      "Reward: 941.96, Ewma Reward: 607.12\n",
      "Reward: 153.39, Ewma Reward: 602.58\n",
      "Reward: 127.44, Ewma Reward: 597.83\n",
      "Reward: 1066.23, Ewma Reward: 602.51\n",
      "Reward: 1290.57, Ewma Reward: 609.39\n",
      "Reward: 726.57, Ewma Reward: 610.56\n",
      "Reward: 327.27, Ewma Reward: 607.73\n",
      "Reward: 1551.36, Ewma Reward: 617.17\n",
      "Reward: 1160.17, Ewma Reward: 622.60\n",
      "Reward: -422.02, Ewma Reward: 612.15\n",
      "Reward: -195.64, Ewma Reward: 604.07\n",
      "Reward: 1278.14, Ewma Reward: 610.81\n",
      "Reward: 1007.89, Ewma Reward: 614.78\n",
      "Reward: 259.67, Ewma Reward: 611.23\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 652          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 920          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031305016 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00463      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 232          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "Reward: 125.12, Ewma Reward: 606.37\n",
      "Reward: 298.24, Ewma Reward: 603.29\n",
      "Reward: 883.14, Ewma Reward: 606.09\n",
      "Reward: 63.39, Ewma Reward: 600.66\n",
      "Reward: 1151.34, Ewma Reward: 606.17\n",
      "Reward: -287.88, Ewma Reward: 597.23\n",
      "Reward: 163.11, Ewma Reward: 592.89\n",
      "Reward: 657.16, Ewma Reward: 593.53\n",
      "Reward: 593.57, Ewma Reward: 593.53\n",
      "Reward: -284.20, Ewma Reward: 584.75\n",
      "Reward: 1300.19, Ewma Reward: 591.91\n",
      "Reward: 749.09, Ewma Reward: 593.48\n",
      "Reward: 851.47, Ewma Reward: 596.06\n",
      "Reward: 1036.91, Ewma Reward: 600.47\n",
      "Reward: 151.71, Ewma Reward: 595.98\n",
      "Reward: 928.69, Ewma Reward: 599.31\n",
      "Reward: -112.62, Ewma Reward: 592.19\n",
      "Reward: 580.55, Ewma Reward: 592.07\n",
      "Reward: 714.21, Ewma Reward: 593.29\n",
      "Reward: 274.09, Ewma Reward: 590.10\n",
      "Reward: 586.46, Ewma Reward: 590.06\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 605          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 908          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028409609 |\n",
      "|    clip_fraction        | 0.00314      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.000836    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 404          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00043     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 848          |\n",
      "------------------------------------------\n",
      "Reward: 1268.58, Ewma Reward: 596.85\n",
      "Reward: -659.89, Ewma Reward: 584.28\n",
      "Reward: 1074.50, Ewma Reward: 589.18\n",
      "Reward: 517.90, Ewma Reward: 588.47\n",
      "Reward: 464.17, Ewma Reward: 587.23\n",
      "Reward: -183.02, Ewma Reward: 579.53\n",
      "Reward: 555.76, Ewma Reward: 579.29\n",
      "Reward: -62.24, Ewma Reward: 572.87\n",
      "Reward: 452.61, Ewma Reward: 571.67\n",
      "Reward: 1296.48, Ewma Reward: 578.92\n",
      "Reward: 727.47, Ewma Reward: 580.40\n",
      "Reward: 619.72, Ewma Reward: 580.80\n",
      "Reward: 71.47, Ewma Reward: 575.70\n",
      "Reward: 151.39, Ewma Reward: 571.46\n",
      "Reward: 993.36, Ewma Reward: 575.68\n",
      "Reward: 770.22, Ewma Reward: 577.63\n",
      "Reward: 539.70, Ewma Reward: 577.25\n",
      "Reward: 169.70, Ewma Reward: 573.17\n",
      "Reward: 1077.47, Ewma Reward: 578.21\n",
      "Reward: 94.55, Ewma Reward: 573.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 582          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 904          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011680897 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 314          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000558    |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 646          |\n",
      "------------------------------------------\n",
      "Reward: 390.40, Ewma Reward: 571.55\n",
      "Reward: 881.90, Ewma Reward: 574.65\n",
      "Reward: 374.90, Ewma Reward: 572.65\n",
      "Reward: 865.16, Ewma Reward: 575.58\n",
      "Reward: 569.38, Ewma Reward: 575.52\n",
      "Reward: 319.15, Ewma Reward: 572.95\n",
      "Reward: -186.30, Ewma Reward: 565.36\n",
      "Reward: 407.15, Ewma Reward: 563.78\n",
      "Reward: 59.19, Ewma Reward: 558.73\n",
      "Reward: 953.36, Ewma Reward: 562.68\n",
      "Reward: 391.28, Ewma Reward: 560.96\n",
      "Reward: 823.36, Ewma Reward: 563.59\n",
      "Reward: 1214.25, Ewma Reward: 570.10\n",
      "Reward: 1068.61, Ewma Reward: 575.08\n",
      "Reward: 1305.58, Ewma Reward: 582.39\n",
      "Reward: 124.40, Ewma Reward: 577.81\n",
      "Reward: -290.58, Ewma Reward: 569.12\n",
      "Reward: -4.80, Ewma Reward: 563.38\n",
      "Reward: 963.62, Ewma Reward: 567.38\n",
      "Reward: -45.29, Ewma Reward: 561.26\n",
      "Reward: 777.85, Ewma Reward: 563.42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 508          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 904          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018212756 |\n",
      "|    clip_fraction        | 0.00807      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00015      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 298          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000673    |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 600          |\n",
      "------------------------------------------\n",
      "Reward: 79.22, Ewma Reward: 558.58\n",
      "Reward: 740.51, Ewma Reward: 560.40\n",
      "Reward: 288.99, Ewma Reward: 557.69\n",
      "Reward: 910.69, Ewma Reward: 561.22\n",
      "Reward: 190.10, Ewma Reward: 557.51\n",
      "Reward: 1138.16, Ewma Reward: 563.31\n",
      "Reward: 81.21, Ewma Reward: 558.49\n",
      "Reward: 1342.16, Ewma Reward: 566.33\n",
      "Reward: 738.04, Ewma Reward: 568.05\n",
      "Reward: 1331.61, Ewma Reward: 575.68\n",
      "Reward: 152.51, Ewma Reward: 571.45\n",
      "Reward: 126.85, Ewma Reward: 567.00\n",
      "Reward: 1064.05, Ewma Reward: 571.97\n",
      "Reward: 170.94, Ewma Reward: 567.96\n",
      "Reward: 947.86, Ewma Reward: 571.76\n",
      "Reward: 258.81, Ewma Reward: 568.63\n",
      "Reward: 1372.55, Ewma Reward: 576.67\n",
      "Reward: 924.30, Ewma Reward: 580.15\n",
      "Reward: 747.18, Ewma Reward: 581.82\n",
      "Reward: 1181.03, Ewma Reward: 587.81\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 566          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025623583 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.00547      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 327          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000902    |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 650          |\n",
      "------------------------------------------\n",
      "Reward: 363.29, Ewma Reward: 585.57\n",
      "Reward: 1149.11, Ewma Reward: 591.20\n",
      "Reward: 368.50, Ewma Reward: 588.97\n",
      "Reward: 33.30, Ewma Reward: 583.42\n",
      "Reward: 120.49, Ewma Reward: 578.79\n",
      "Reward: 1204.84, Ewma Reward: 585.05\n",
      "Reward: -158.31, Ewma Reward: 577.61\n",
      "Reward: 795.53, Ewma Reward: 579.79\n",
      "Reward: 664.23, Ewma Reward: 580.64\n",
      "Reward: 161.50, Ewma Reward: 576.45\n",
      "Reward: 850.07, Ewma Reward: 579.18\n",
      "Reward: 1089.03, Ewma Reward: 584.28\n",
      "Reward: 174.24, Ewma Reward: 580.18\n",
      "Reward: 364.05, Ewma Reward: 578.02\n",
      "Reward: 360.52, Ewma Reward: 575.84\n",
      "Reward: 256.68, Ewma Reward: 572.65\n",
      "Reward: 389.26, Ewma Reward: 570.82\n",
      "Reward: 1193.99, Ewma Reward: 577.05\n",
      "Reward: 946.18, Ewma Reward: 580.74\n",
      "Reward: -312.85, Ewma Reward: 571.81\n",
      "Reward: 788.07, Ewma Reward: 573.97\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 546          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 895          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008964672 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -5.9e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 421          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -9.26e-05    |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 858          |\n",
      "------------------------------------------\n",
      "Reward: 967.75, Ewma Reward: 577.91\n",
      "Reward: 75.18, Ewma Reward: 572.88\n",
      "Reward: 628.44, Ewma Reward: 573.44\n",
      "Reward: 294.75, Ewma Reward: 570.65\n",
      "Reward: 930.96, Ewma Reward: 574.25\n",
      "Reward: 986.66, Ewma Reward: 578.38\n",
      "Reward: 793.91, Ewma Reward: 580.53\n",
      "Reward: -183.95, Ewma Reward: 572.89\n",
      "Reward: 637.02, Ewma Reward: 573.53\n",
      "Reward: 650.13, Ewma Reward: 574.29\n",
      "Reward: 705.71, Ewma Reward: 575.61\n",
      "Reward: 1027.39, Ewma Reward: 580.13\n",
      "Reward: 941.91, Ewma Reward: 583.74\n",
      "Reward: 1145.10, Ewma Reward: 589.36\n",
      "Reward: 874.22, Ewma Reward: 592.21\n",
      "Reward: 1130.15, Ewma Reward: 597.59\n",
      "Reward: 114.13, Ewma Reward: 592.75\n",
      "Reward: 8.56, Ewma Reward: 586.91\n",
      "Reward: 244.54, Ewma Reward: 583.48\n",
      "Reward: 1237.32, Ewma Reward: 590.02\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 581          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 896          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 301          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024660807 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.000122    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 306          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00021     |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 619          |\n",
      "------------------------------------------\n",
      "Reward: -61.29, Ewma Reward: 583.51\n",
      "Reward: 361.36, Ewma Reward: 581.29\n",
      "Reward: 1178.47, Ewma Reward: 587.26\n",
      "Reward: 416.65, Ewma Reward: 585.55\n",
      "Reward: 1081.82, Ewma Reward: 590.52\n",
      "Reward: 436.82, Ewma Reward: 588.98\n",
      "Reward: 1322.01, Ewma Reward: 596.31\n",
      "Reward: 1009.17, Ewma Reward: 600.44\n",
      "Reward: 183.57, Ewma Reward: 596.27\n",
      "Reward: 900.99, Ewma Reward: 599.32\n",
      "Reward: 796.28, Ewma Reward: 601.29\n",
      "Reward: 702.84, Ewma Reward: 602.30\n",
      "Reward: 847.74, Ewma Reward: 604.76\n",
      "Reward: 354.50, Ewma Reward: 602.25\n",
      "Reward: 1348.80, Ewma Reward: 609.72\n",
      "Reward: 1141.54, Ewma Reward: 615.04\n",
      "Reward: 500.98, Ewma Reward: 613.90\n",
      "Reward: 961.23, Ewma Reward: 617.37\n",
      "Reward: 1310.29, Ewma Reward: 624.30\n",
      "Reward: 343.20, Ewma Reward: 621.49\n",
      "Reward: 933.41, Ewma Reward: 624.61\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 632           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 894           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 311           |\n",
      "|    total_timesteps      | 278528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035964284 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.37         |\n",
      "|    explained_variance   | -0.000162     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 351           |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    std                  | 0.953         |\n",
      "|    value_loss           | 719           |\n",
      "-------------------------------------------\n",
      "Reward: 988.39, Ewma Reward: 628.25\n",
      "Reward: 80.33, Ewma Reward: 622.77\n",
      "Reward: 367.84, Ewma Reward: 620.22\n",
      "Reward: 1002.63, Ewma Reward: 624.04\n",
      "Reward: 1331.76, Ewma Reward: 631.12\n",
      "Reward: 1087.60, Ewma Reward: 635.68\n",
      "Reward: 963.93, Ewma Reward: 638.97\n",
      "Reward: 1149.80, Ewma Reward: 644.07\n",
      "Reward: 743.62, Ewma Reward: 645.07\n",
      "Reward: 600.93, Ewma Reward: 644.63\n",
      "Reward: 710.52, Ewma Reward: 645.29\n",
      "Reward: 938.23, Ewma Reward: 648.22\n",
      "Reward: 759.52, Ewma Reward: 649.33\n",
      "Reward: 764.51, Ewma Reward: 650.48\n",
      "Reward: 1409.25, Ewma Reward: 658.07\n",
      "Reward: 570.88, Ewma Reward: 657.20\n",
      "Reward: 515.43, Ewma Reward: 655.78\n",
      "Reward: 106.98, Ewma Reward: 650.29\n",
      "Reward: 553.18, Ewma Reward: 649.32\n",
      "Reward: 36.92, Ewma Reward: 643.20\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017604483 |\n",
      "|    clip_fraction        | 0.00311      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -9.62e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 449          |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000437    |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 919          |\n",
      "------------------------------------------\n",
      "Reward: 692.41, Ewma Reward: 643.69\n",
      "Reward: 359.92, Ewma Reward: 640.85\n",
      "Reward: 799.59, Ewma Reward: 642.44\n",
      "Reward: 319.10, Ewma Reward: 639.21\n",
      "Reward: 347.59, Ewma Reward: 636.29\n",
      "Reward: 710.56, Ewma Reward: 637.03\n",
      "Reward: 347.34, Ewma Reward: 634.13\n",
      "Reward: 982.02, Ewma Reward: 637.61\n",
      "Reward: 598.44, Ewma Reward: 637.22\n",
      "Reward: 635.28, Ewma Reward: 637.20\n",
      "Reward: 920.24, Ewma Reward: 640.03\n",
      "Reward: 343.60, Ewma Reward: 637.07\n",
      "Reward: 1180.84, Ewma Reward: 642.51\n",
      "Reward: 414.59, Ewma Reward: 640.23\n",
      "Reward: 114.71, Ewma Reward: 634.97\n",
      "Reward: 675.85, Ewma Reward: 635.38\n",
      "Reward: 451.55, Ewma Reward: 633.54\n",
      "Reward: 586.48, Ewma Reward: 633.07\n",
      "Reward: 1014.68, Ewma Reward: 636.89\n",
      "Reward: -143.47, Ewma Reward: 629.08\n",
      "Reward: -39.83, Ewma Reward: 622.40\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 642           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 900           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 327           |\n",
      "|    total_timesteps      | 294912        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048512264 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.37         |\n",
      "|    explained_variance   | -8.95e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 404           |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -8.89e-05     |\n",
      "|    std                  | 0.951         |\n",
      "|    value_loss           | 810           |\n",
      "-------------------------------------------\n",
      "Reward: 1114.97, Ewma Reward: 627.32\n",
      "Reward: 895.45, Ewma Reward: 630.00\n",
      "Reward: -99.62, Ewma Reward: 622.71\n",
      "Reward: 901.96, Ewma Reward: 625.50\n",
      "Reward: 1055.05, Ewma Reward: 629.79\n",
      "Reward: 455.06, Ewma Reward: 628.05\n",
      "Reward: -30.69, Ewma Reward: 621.46\n",
      "Reward: 10.98, Ewma Reward: 615.35\n",
      "Reward: 273.70, Ewma Reward: 611.94\n",
      "Reward: 89.23, Ewma Reward: 606.71\n",
      "Reward: 640.18, Ewma Reward: 607.05\n",
      "Reward: 726.73, Ewma Reward: 608.24\n",
      "Reward: 200.77, Ewma Reward: 604.17\n",
      "Reward: 1509.25, Ewma Reward: 613.22\n",
      "Reward: 786.67, Ewma Reward: 614.95\n",
      "Reward: 1586.65, Ewma Reward: 624.67\n",
      "Reward: 209.94, Ewma Reward: 620.52\n",
      "Reward: -43.07, Ewma Reward: 613.89\n",
      "Reward: 891.60, Ewma Reward: 616.66\n",
      "Reward: 38.52, Ewma Reward: 610.88\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 654          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 902          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 335          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.293843e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.000351     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -3.9e-05     |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 460          |\n",
      "------------------------------------------\n",
      "Reward: 561.43, Ewma Reward: 610.39\n",
      "Reward: -286.63, Ewma Reward: 601.42\n",
      "Reward: 53.19, Ewma Reward: 595.94\n",
      "Reward: 468.01, Ewma Reward: 594.66\n",
      "Reward: 869.81, Ewma Reward: 597.41\n",
      "Reward: 46.59, Ewma Reward: 591.90\n",
      "Reward: 731.72, Ewma Reward: 593.30\n",
      "Reward: 212.89, Ewma Reward: 589.49\n",
      "Reward: -431.70, Ewma Reward: 579.28\n",
      "Reward: 1112.54, Ewma Reward: 584.61\n",
      "Reward: 9.81, Ewma Reward: 578.87\n",
      "Reward: 51.49, Ewma Reward: 573.59\n",
      "Reward: 190.78, Ewma Reward: 569.76\n",
      "Reward: -19.55, Ewma Reward: 563.87\n",
      "Reward: -278.49, Ewma Reward: 555.45\n",
      "Reward: 424.58, Ewma Reward: 554.14\n",
      "Reward: 391.94, Ewma Reward: 552.52\n",
      "Reward: 1179.81, Ewma Reward: 558.79\n",
      "Reward: 414.70, Ewma Reward: 557.35\n",
      "Reward: 744.61, Ewma Reward: 559.22\n",
      "Reward: 1243.33, Ewma Reward: 566.06\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 595           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 901           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 345           |\n",
      "|    total_timesteps      | 311296        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028318603 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.36         |\n",
      "|    explained_variance   | -0.00014      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 352           |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -4.91e-05     |\n",
      "|    std                  | 0.948         |\n",
      "|    value_loss           | 709           |\n",
      "-------------------------------------------\n",
      "Reward: 744.49, Ewma Reward: 567.85\n",
      "Reward: 1091.89, Ewma Reward: 573.09\n",
      "Reward: 933.03, Ewma Reward: 576.69\n",
      "Reward: 680.43, Ewma Reward: 577.72\n",
      "Reward: 27.72, Ewma Reward: 572.22\n",
      "Reward: -66.51, Ewma Reward: 565.84\n",
      "Reward: 876.40, Ewma Reward: 568.94\n",
      "Reward: 127.00, Ewma Reward: 564.52\n",
      "Reward: 383.82, Ewma Reward: 562.72\n",
      "Reward: 929.38, Ewma Reward: 566.38\n",
      "Reward: 475.30, Ewma Reward: 565.47\n",
      "Reward: 1.50, Ewma Reward: 559.83\n",
      "Reward: 763.45, Ewma Reward: 561.87\n",
      "Reward: 1160.81, Ewma Reward: 567.86\n",
      "Reward: 829.57, Ewma Reward: 570.47\n",
      "Reward: 452.52, Ewma Reward: 569.30\n",
      "Reward: 810.45, Ewma Reward: 571.71\n",
      "Reward: 327.13, Ewma Reward: 569.26\n",
      "Reward: 663.71, Ewma Reward: 570.21\n",
      "Reward: 474.40, Ewma Reward: 569.25\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 555          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 899          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020417096 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.000167    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.941        |\n",
      "|    value_loss           | 522          |\n",
      "------------------------------------------\n",
      "Reward: 212.36, Ewma Reward: 565.68\n",
      "Reward: 873.77, Ewma Reward: 568.76\n",
      "Reward: 1022.70, Ewma Reward: 573.30\n",
      "Reward: 571.60, Ewma Reward: 573.28\n",
      "Reward: 214.68, Ewma Reward: 569.70\n",
      "Reward: 950.68, Ewma Reward: 573.51\n",
      "Reward: -375.44, Ewma Reward: 564.02\n",
      "Reward: 607.99, Ewma Reward: 564.46\n",
      "Reward: -375.32, Ewma Reward: 555.06\n",
      "Reward: -6.33, Ewma Reward: 549.44\n",
      "Reward: 974.78, Ewma Reward: 553.70\n",
      "Reward: 1057.51, Ewma Reward: 558.74\n",
      "Reward: 191.57, Ewma Reward: 555.06\n",
      "Reward: 220.15, Ewma Reward: 551.72\n",
      "Reward: 1169.89, Ewma Reward: 557.90\n",
      "Reward: 532.98, Ewma Reward: 557.65\n",
      "Reward: 846.24, Ewma Reward: 560.53\n",
      "Reward: -99.22, Ewma Reward: 553.94\n",
      "Reward: 1190.62, Ewma Reward: 560.30\n",
      "Reward: 68.27, Ewma Reward: 555.38\n",
      "Reward: 1417.69, Ewma Reward: 564.01\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 513          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 895          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008951331 |\n",
      "|    clip_fraction        | 0.000317     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.00228      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 260          |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000302    |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 540          |\n",
      "------------------------------------------\n",
      "Reward: -271.31, Ewma Reward: 555.65\n",
      "Reward: -315.26, Ewma Reward: 546.94\n",
      "Reward: 1485.61, Ewma Reward: 556.33\n",
      "Reward: 309.14, Ewma Reward: 553.86\n",
      "Reward: 531.63, Ewma Reward: 553.64\n",
      "Reward: 678.53, Ewma Reward: 554.88\n",
      "Reward: 916.73, Ewma Reward: 558.50\n",
      "Reward: 993.48, Ewma Reward: 562.85\n",
      "Reward: 583.72, Ewma Reward: 563.06\n",
      "Reward: -18.42, Ewma Reward: 557.25\n",
      "Reward: 892.97, Ewma Reward: 560.60\n",
      "Reward: 891.92, Ewma Reward: 563.92\n",
      "Reward: 1178.16, Ewma Reward: 570.06\n",
      "Reward: -106.24, Ewma Reward: 563.30\n",
      "Reward: 135.89, Ewma Reward: 559.02\n",
      "Reward: -98.70, Ewma Reward: 552.45\n",
      "Reward: -296.61, Ewma Reward: 543.95\n",
      "Reward: 48.14, Ewma Reward: 539.00\n",
      "Reward: 145.23, Ewma Reward: 535.06\n",
      "Reward: 1094.26, Ewma Reward: 540.65\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 486          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 894          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 375          |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022266265 |\n",
      "|    clip_fraction        | 0.00568      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.000801     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 357          |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000443    |\n",
      "|    std                  | 0.928        |\n",
      "|    value_loss           | 737          |\n",
      "------------------------------------------\n",
      "Reward: 528.40, Ewma Reward: 540.53\n",
      "Reward: 1428.95, Ewma Reward: 549.41\n",
      "Reward: 818.87, Ewma Reward: 552.11\n",
      "Reward: 356.02, Ewma Reward: 550.15\n",
      "Reward: 486.85, Ewma Reward: 549.51\n",
      "Reward: 601.25, Ewma Reward: 550.03\n",
      "Reward: -7.46, Ewma Reward: 544.46\n",
      "Reward: 753.42, Ewma Reward: 546.55\n",
      "Reward: -36.29, Ewma Reward: 540.72\n",
      "Reward: 807.30, Ewma Reward: 543.38\n",
      "Reward: 912.36, Ewma Reward: 547.07\n",
      "Reward: 509.57, Ewma Reward: 546.70\n",
      "Reward: 930.12, Ewma Reward: 550.53\n",
      "Reward: 333.17, Ewma Reward: 548.36\n",
      "Reward: 255.36, Ewma Reward: 545.43\n",
      "Reward: -32.18, Ewma Reward: 539.65\n",
      "Reward: 970.58, Ewma Reward: 543.96\n",
      "Reward: 383.54, Ewma Reward: 542.36\n",
      "Reward: 1189.86, Ewma Reward: 548.83\n",
      "Reward: 1067.07, Ewma Reward: 554.01\n",
      "Reward: 1067.58, Ewma Reward: 559.15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 524         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 890         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002788003 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.000106    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.000728   |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 646         |\n",
      "-----------------------------------------\n",
      "Reward: -128.80, Ewma Reward: 552.27\n",
      "Reward: 1301.15, Ewma Reward: 559.76\n",
      "Reward: 559.63, Ewma Reward: 559.76\n",
      "Reward: 1255.26, Ewma Reward: 566.71\n",
      "Reward: -51.65, Ewma Reward: 560.53\n",
      "Reward: 627.44, Ewma Reward: 561.20\n",
      "Reward: 1148.80, Ewma Reward: 567.07\n",
      "Reward: 1360.66, Ewma Reward: 575.01\n",
      "Reward: 161.52, Ewma Reward: 570.88\n",
      "Reward: 1195.95, Ewma Reward: 577.13\n",
      "Reward: 1025.04, Ewma Reward: 581.61\n",
      "Reward: 1177.88, Ewma Reward: 587.57\n",
      "Reward: 513.45, Ewma Reward: 586.83\n",
      "Reward: 1245.27, Ewma Reward: 593.41\n",
      "Reward: -125.41, Ewma Reward: 586.22\n",
      "Reward: 241.68, Ewma Reward: 582.78\n",
      "Reward: 385.01, Ewma Reward: 580.80\n",
      "Reward: 374.24, Ewma Reward: 578.73\n",
      "Reward: 738.88, Ewma Reward: 580.34\n",
      "Reward: 707.90, Ewma Reward: 581.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 569          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 886          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022008142 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.0346       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 331          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000807    |\n",
      "|    std                  | 0.925        |\n",
      "|    value_loss           | 681          |\n",
      "------------------------------------------\n",
      "Reward: 338.99, Ewma Reward: 579.19\n",
      "Reward: 294.53, Ewma Reward: 576.34\n",
      "Reward: 1254.23, Ewma Reward: 583.12\n",
      "Reward: 200.41, Ewma Reward: 579.29\n",
      "Reward: 322.59, Ewma Reward: 576.72\n",
      "Reward: 728.89, Ewma Reward: 578.25\n",
      "Reward: 186.58, Ewma Reward: 574.33\n",
      "Reward: 807.03, Ewma Reward: 576.66\n",
      "Reward: -303.49, Ewma Reward: 567.85\n",
      "Reward: 422.79, Ewma Reward: 566.40\n",
      "Reward: -209.60, Ewma Reward: 558.64\n",
      "Reward: 3.66, Ewma Reward: 553.09\n",
      "Reward: 22.16, Ewma Reward: 547.78\n",
      "Reward: 1182.90, Ewma Reward: 554.14\n",
      "Reward: 204.63, Ewma Reward: 550.64\n",
      "Reward: -293.81, Ewma Reward: 542.20\n",
      "Reward: 75.00, Ewma Reward: 537.52\n",
      "Reward: 210.93, Ewma Reward: 534.26\n",
      "Reward: -408.60, Ewma Reward: 524.83\n",
      "Reward: 876.70, Ewma Reward: 528.35\n",
      "Reward: 697.08, Ewma Reward: 530.04\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 516         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 883         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001516098 |\n",
      "|    clip_fraction        | 0.00165     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.000642   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 421         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.000437   |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 861         |\n",
      "-----------------------------------------\n",
      "Reward: 853.02, Ewma Reward: 533.27\n",
      "Reward: 1476.56, Ewma Reward: 542.70\n",
      "Reward: 638.90, Ewma Reward: 543.66\n",
      "Reward: 351.48, Ewma Reward: 541.74\n",
      "Reward: 1467.91, Ewma Reward: 551.00\n",
      "Reward: 1156.42, Ewma Reward: 557.05\n",
      "Reward: -86.28, Ewma Reward: 550.62\n",
      "Reward: 683.90, Ewma Reward: 551.95\n",
      "Reward: 813.04, Ewma Reward: 554.57\n",
      "Reward: -80.58, Ewma Reward: 548.21\n",
      "Reward: 1040.28, Ewma Reward: 553.13\n",
      "Reward: 583.73, Ewma Reward: 553.44\n",
      "Reward: 617.29, Ewma Reward: 554.08\n",
      "Reward: -19.23, Ewma Reward: 548.35\n",
      "Reward: 879.44, Ewma Reward: 551.66\n",
      "Reward: 1320.72, Ewma Reward: 559.35\n",
      "Reward: 639.65, Ewma Reward: 560.15\n",
      "Reward: 272.05, Ewma Reward: 557.27\n",
      "Reward: 1364.39, Ewma Reward: 565.34\n",
      "Reward: 946.42, Ewma Reward: 569.15\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 579          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 881          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019519354 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.00415      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 243          |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 484          |\n",
      "------------------------------------------\n",
      "Reward: 462.11, Ewma Reward: 568.08\n",
      "Reward: 743.59, Ewma Reward: 569.84\n",
      "Reward: 402.48, Ewma Reward: 568.16\n",
      "Reward: 879.20, Ewma Reward: 571.27\n",
      "Reward: 516.30, Ewma Reward: 570.72\n",
      "Reward: 181.26, Ewma Reward: 566.83\n",
      "Reward: 673.61, Ewma Reward: 567.90\n",
      "Reward: 1129.47, Ewma Reward: 573.51\n",
      "Reward: 409.48, Ewma Reward: 571.87\n",
      "Reward: 894.52, Ewma Reward: 575.10\n",
      "Reward: 277.70, Ewma Reward: 572.12\n",
      "Reward: 188.87, Ewma Reward: 568.29\n",
      "Reward: -99.14, Ewma Reward: 561.62\n",
      "Reward: 1234.75, Ewma Reward: 568.35\n",
      "Reward: 986.88, Ewma Reward: 572.53\n",
      "Reward: 1253.30, Ewma Reward: 579.34\n",
      "Reward: 995.39, Ewma Reward: 583.50\n",
      "Reward: 50.63, Ewma Reward: 578.17\n",
      "Reward: 87.42, Ewma Reward: 573.27\n",
      "Reward: 1061.28, Ewma Reward: 578.15\n",
      "Reward: 837.12, Ewma Reward: 580.74\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 590          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 880          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 428          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035617496 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.00225     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 433          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    std                  | 0.934        |\n",
      "|    value_loss           | 879          |\n",
      "------------------------------------------\n",
      "Reward: -247.19, Ewma Reward: 572.46\n",
      "Reward: 525.43, Ewma Reward: 571.99\n",
      "Reward: 495.04, Ewma Reward: 571.22\n",
      "Reward: 425.81, Ewma Reward: 569.76\n",
      "Reward: 1370.12, Ewma Reward: 577.77\n",
      "Reward: 851.28, Ewma Reward: 580.50\n",
      "Reward: 1108.45, Ewma Reward: 585.78\n",
      "Reward: 533.22, Ewma Reward: 585.26\n",
      "Reward: 831.96, Ewma Reward: 587.72\n",
      "Reward: -574.06, Ewma Reward: 576.10\n",
      "Reward: -409.93, Ewma Reward: 566.24\n",
      "Reward: -22.04, Ewma Reward: 560.36\n",
      "Reward: 168.88, Ewma Reward: 556.45\n",
      "Reward: 875.59, Ewma Reward: 559.64\n",
      "Reward: 986.75, Ewma Reward: 563.91\n",
      "Reward: 880.51, Ewma Reward: 567.08\n",
      "Reward: 957.60, Ewma Reward: 570.98\n",
      "Reward: 857.69, Ewma Reward: 573.85\n",
      "Reward: 152.78, Ewma Reward: 569.64\n",
      "Reward: 312.47, Ewma Reward: 567.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 573          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 878          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022236158 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -9.54e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 312          |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.000834    |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 630          |\n",
      "------------------------------------------\n",
      "Reward: 939.77, Ewma Reward: 570.79\n",
      "Reward: 249.14, Ewma Reward: 567.58\n",
      "Reward: -111.97, Ewma Reward: 560.78\n",
      "Reward: 1057.16, Ewma Reward: 565.74\n",
      "Reward: 108.68, Ewma Reward: 561.17\n",
      "Reward: -380.32, Ewma Reward: 551.76\n",
      "Reward: -22.61, Ewma Reward: 546.01\n",
      "Reward: 973.18, Ewma Reward: 550.29\n",
      "Reward: 915.29, Ewma Reward: 553.94\n",
      "Reward: 242.97, Ewma Reward: 550.83\n",
      "Reward: 808.31, Ewma Reward: 553.40\n",
      "Reward: 1226.69, Ewma Reward: 560.13\n",
      "Reward: 291.78, Ewma Reward: 557.45\n",
      "Reward: 704.54, Ewma Reward: 558.92\n",
      "Reward: -69.34, Ewma Reward: 552.64\n",
      "Reward: 370.81, Ewma Reward: 550.82\n",
      "Reward: -105.16, Ewma Reward: 544.26\n",
      "Reward: 125.56, Ewma Reward: 540.07\n",
      "Reward: 786.08, Ewma Reward: 542.53\n",
      "Reward: 823.08, Ewma Reward: 545.34\n",
      "Reward: 445.45, Ewma Reward: 544.34\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 523          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 880          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 446          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011672834 |\n",
      "|    clip_fraction        | 0.000403     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.00108      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 338          |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000224    |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 660          |\n",
      "------------------------------------------\n",
      "Reward: 1325.55, Ewma Reward: 552.15\n",
      "Reward: 1531.45, Ewma Reward: 561.95\n",
      "Reward: 40.98, Ewma Reward: 556.74\n",
      "Reward: 1089.78, Ewma Reward: 562.07\n",
      "Reward: 26.64, Ewma Reward: 556.71\n",
      "Reward: 1209.00, Ewma Reward: 563.24\n",
      "Reward: 479.79, Ewma Reward: 562.40\n",
      "Reward: 894.06, Ewma Reward: 565.72\n",
      "Reward: 310.58, Ewma Reward: 563.17\n",
      "Reward: 706.50, Ewma Reward: 564.60\n",
      "Reward: 1388.30, Ewma Reward: 572.84\n",
      "Reward: 2.38, Ewma Reward: 567.13\n",
      "Reward: 653.77, Ewma Reward: 568.00\n",
      "Reward: 281.95, Ewma Reward: 565.14\n",
      "Reward: -4.35, Ewma Reward: 559.44\n",
      "Reward: 1169.46, Ewma Reward: 565.54\n",
      "Reward: 1385.88, Ewma Reward: 573.75\n",
      "Reward: 1741.83, Ewma Reward: 585.43\n",
      "Reward: 999.59, Ewma Reward: 589.57\n",
      "Reward: 516.66, Ewma Reward: 588.84\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 610         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 883         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002231736 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 9.89e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 237         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 493         |\n",
      "-----------------------------------------\n",
      "Reward: 327.44, Ewma Reward: 586.23\n",
      "Reward: 1353.38, Ewma Reward: 593.90\n",
      "Reward: 1103.51, Ewma Reward: 598.99\n",
      "Reward: 562.49, Ewma Reward: 598.63\n",
      "Reward: 338.16, Ewma Reward: 596.02\n",
      "Reward: 1529.74, Ewma Reward: 605.36\n",
      "Reward: 15.20, Ewma Reward: 599.46\n",
      "Reward: 54.63, Ewma Reward: 594.01\n",
      "Reward: 866.97, Ewma Reward: 596.74\n",
      "Reward: 565.01, Ewma Reward: 596.42\n",
      "Reward: 1136.98, Ewma Reward: 601.83\n",
      "Reward: -127.83, Ewma Reward: 594.53\n",
      "Reward: 712.97, Ewma Reward: 595.72\n",
      "Reward: 1047.74, Ewma Reward: 600.24\n",
      "Reward: 696.91, Ewma Reward: 601.20\n",
      "Reward: 1100.85, Ewma Reward: 606.20\n",
      "Reward: 1259.50, Ewma Reward: 612.73\n",
      "Reward: 95.30, Ewma Reward: 607.56\n",
      "Reward: 654.11, Ewma Reward: 608.02\n",
      "Reward: 1281.20, Ewma Reward: 614.76\n",
      "Reward: 1019.98, Ewma Reward: 618.81\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 624           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 886           |\n",
      "|    iterations           | 50            |\n",
      "|    time_elapsed         | 462           |\n",
      "|    total_timesteps      | 409600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020787847 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 3.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 496           |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -3.35e-05     |\n",
      "|    std                  | 0.936         |\n",
      "|    value_loss           | 1.04e+03      |\n",
      "-------------------------------------------\n",
      "Reward: 401.68, Ewma Reward: 616.64\n",
      "Reward: 472.75, Ewma Reward: 615.20\n",
      "Reward: 826.47, Ewma Reward: 617.31\n",
      "Reward: 206.50, Ewma Reward: 613.20\n",
      "Reward: 642.00, Ewma Reward: 613.49\n",
      "Reward: 416.66, Ewma Reward: 611.52\n",
      "Reward: 455.14, Ewma Reward: 609.96\n",
      "Reward: 365.86, Ewma Reward: 607.52\n",
      "Reward: 471.15, Ewma Reward: 606.15\n",
      "Reward: 296.73, Ewma Reward: 603.06\n",
      "Reward: 1459.31, Ewma Reward: 611.62\n",
      "Reward: 730.40, Ewma Reward: 612.81\n",
      "Reward: 928.84, Ewma Reward: 615.97\n",
      "Reward: 623.75, Ewma Reward: 616.05\n",
      "Reward: 800.28, Ewma Reward: 617.89\n",
      "Reward: 443.07, Ewma Reward: 616.14\n",
      "Reward: 802.69, Ewma Reward: 618.01\n",
      "Reward: 119.69, Ewma Reward: 613.02\n",
      "Reward: 731.82, Ewma Reward: 614.21\n",
      "Reward: 649.66, Ewma Reward: 614.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 624         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 891         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002193865 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 5.64e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 435         |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.000962   |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 894         |\n",
      "-----------------------------------------\n",
      "Reward: 753.63, Ewma Reward: 615.96\n",
      "Reward: 998.79, Ewma Reward: 619.79\n",
      "Reward: 157.13, Ewma Reward: 615.16\n",
      "Reward: 156.29, Ewma Reward: 610.57\n",
      "Reward: 470.23, Ewma Reward: 609.17\n",
      "Reward: 1006.22, Ewma Reward: 613.14\n",
      "Reward: 396.95, Ewma Reward: 610.98\n",
      "Reward: 592.33, Ewma Reward: 610.79\n",
      "Reward: 917.83, Ewma Reward: 613.86\n",
      "Reward: 607.75, Ewma Reward: 613.80\n",
      "Reward: 523.72, Ewma Reward: 612.90\n",
      "Reward: 757.78, Ewma Reward: 614.35\n",
      "Reward: 1296.54, Ewma Reward: 621.17\n",
      "Reward: 622.31, Ewma Reward: 621.18\n",
      "Reward: 814.46, Ewma Reward: 623.11\n",
      "Reward: 1453.39, Ewma Reward: 631.42\n",
      "Reward: -428.42, Ewma Reward: 620.82\n",
      "Reward: 621.04, Ewma Reward: 620.82\n",
      "Reward: -216.11, Ewma Reward: 612.45\n",
      "Reward: 565.98, Ewma Reward: 611.99\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 634          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 892          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 477          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012667213 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 1.2e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 192          |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.000351    |\n",
      "|    std                  | 0.935        |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n",
      "Reward: 824.13, Ewma Reward: 614.11\n",
      "Reward: 213.82, Ewma Reward: 610.10\n",
      "Reward: 1040.18, Ewma Reward: 614.41\n",
      "Reward: 1636.73, Ewma Reward: 624.63\n",
      "Reward: 1223.84, Ewma Reward: 630.62\n",
      "Reward: 781.77, Ewma Reward: 632.13\n",
      "Reward: 1538.30, Ewma Reward: 641.19\n",
      "Reward: 91.88, Ewma Reward: 635.70\n",
      "Reward: 1123.42, Ewma Reward: 640.58\n",
      "Reward: 1281.16, Ewma Reward: 646.98\n",
      "Reward: 645.55, Ewma Reward: 646.97\n",
      "Reward: 352.84, Ewma Reward: 644.03\n",
      "Reward: -266.70, Ewma Reward: 634.92\n",
      "Reward: 916.52, Ewma Reward: 637.74\n",
      "Reward: 1238.47, Ewma Reward: 643.74\n",
      "Reward: 961.76, Ewma Reward: 646.92\n",
      "Reward: 562.97, Ewma Reward: 646.08\n",
      "Reward: 422.42, Ewma Reward: 643.85\n",
      "Reward: 427.29, Ewma Reward: 641.68\n",
      "Reward: 908.83, Ewma Reward: 644.35\n",
      "Reward: -146.30, Ewma Reward: 636.45\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 682         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 891         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002865571 |\n",
      "|    clip_fraction        | 0.00333     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 8.27e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 310         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0005     |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 640         |\n",
      "-----------------------------------------\n",
      "Reward: 215.51, Ewma Reward: 632.24\n",
      "Reward: 909.46, Ewma Reward: 635.01\n",
      "Reward: 678.67, Ewma Reward: 635.45\n",
      "Reward: 694.26, Ewma Reward: 636.03\n",
      "Reward: 709.72, Ewma Reward: 636.77\n",
      "Reward: 1155.86, Ewma Reward: 641.96\n",
      "Reward: 964.24, Ewma Reward: 645.19\n",
      "Reward: 374.92, Ewma Reward: 642.48\n",
      "Reward: 1210.60, Ewma Reward: 648.16\n",
      "Reward: 1091.65, Ewma Reward: 652.60\n",
      "Reward: 358.24, Ewma Reward: 649.66\n",
      "Reward: -199.50, Ewma Reward: 641.16\n",
      "Reward: -955.91, Ewma Reward: 625.19\n",
      "Reward: 239.66, Ewma Reward: 621.34\n",
      "Reward: 870.13, Ewma Reward: 623.83\n",
      "Reward: 927.81, Ewma Reward: 626.87\n",
      "Reward: 416.61, Ewma Reward: 624.76\n",
      "Reward: 1023.11, Ewma Reward: 628.75\n",
      "Reward: 1033.28, Ewma Reward: 632.79\n",
      "Reward: -281.27, Ewma Reward: 623.65\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 650        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 886        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 498        |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00292187 |\n",
      "|    clip_fraction        | 0.00627    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.000177   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 462        |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.000401  |\n",
      "|    std                  | 0.936      |\n",
      "|    value_loss           | 939        |\n",
      "----------------------------------------\n",
      "Reward: 604.57, Ewma Reward: 623.46\n",
      "Reward: 702.74, Ewma Reward: 624.25\n",
      "Reward: 501.87, Ewma Reward: 623.03\n",
      "Reward: 1249.65, Ewma Reward: 629.30\n",
      "Reward: 271.77, Ewma Reward: 625.72\n",
      "Reward: 168.86, Ewma Reward: 621.15\n",
      "Reward: 1017.77, Ewma Reward: 625.12\n",
      "Reward: 1235.29, Ewma Reward: 631.22\n",
      "Reward: -14.78, Ewma Reward: 624.76\n",
      "Reward: 1035.35, Ewma Reward: 628.87\n",
      "Reward: -489.77, Ewma Reward: 617.68\n",
      "Reward: 185.55, Ewma Reward: 613.36\n",
      "Reward: 632.17, Ewma Reward: 613.55\n",
      "Reward: 1250.98, Ewma Reward: 619.92\n",
      "Reward: 294.56, Ewma Reward: 616.67\n",
      "Reward: 1362.79, Ewma Reward: 624.13\n",
      "Reward: 1019.56, Ewma Reward: 628.08\n",
      "Reward: 781.96, Ewma Reward: 629.62\n",
      "Reward: 974.08, Ewma Reward: 633.07\n",
      "Reward: 132.06, Ewma Reward: 628.06\n",
      "Reward: 1058.32, Ewma Reward: 632.36\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 642          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 508          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033763545 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 1.97e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 379          |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 776          |\n",
      "------------------------------------------\n",
      "Reward: 776.69, Ewma Reward: 633.80\n",
      "Reward: 303.22, Ewma Reward: 630.50\n",
      "Reward: 1446.80, Ewma Reward: 638.66\n",
      "Reward: -181.78, Ewma Reward: 630.45\n",
      "Reward: 1599.19, Ewma Reward: 640.14\n",
      "Reward: 146.80, Ewma Reward: 635.21\n",
      "Reward: 204.95, Ewma Reward: 630.91\n",
      "Reward: -142.61, Ewma Reward: 623.17\n",
      "Reward: 64.61, Ewma Reward: 617.58\n",
      "Reward: -168.74, Ewma Reward: 609.72\n",
      "Reward: 1398.55, Ewma Reward: 617.61\n",
      "Reward: 545.49, Ewma Reward: 616.89\n",
      "Reward: 1096.42, Ewma Reward: 621.68\n",
      "Reward: 722.58, Ewma Reward: 622.69\n",
      "Reward: 453.44, Ewma Reward: 621.00\n",
      "Reward: 1479.93, Ewma Reward: 629.59\n",
      "Reward: 3.33, Ewma Reward: 623.33\n",
      "Reward: 990.71, Ewma Reward: 627.00\n",
      "Reward: 577.54, Ewma Reward: 626.51\n",
      "Reward: 903.65, Ewma Reward: 629.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 637          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 884          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 518          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030172274 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.000145    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 394          |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 783          |\n",
      "------------------------------------------\n",
      "Reward: 486.01, Ewma Reward: 627.84\n",
      "Reward: 516.37, Ewma Reward: 626.73\n",
      "Reward: 681.70, Ewma Reward: 627.28\n",
      "Reward: -8.93, Ewma Reward: 620.92\n",
      "Reward: 1423.44, Ewma Reward: 628.94\n",
      "Reward: 154.49, Ewma Reward: 624.20\n",
      "Reward: 1061.11, Ewma Reward: 628.57\n",
      "Reward: 943.63, Ewma Reward: 631.72\n",
      "Reward: 129.84, Ewma Reward: 626.70\n",
      "Reward: 218.96, Ewma Reward: 622.62\n",
      "Reward: 1020.15, Ewma Reward: 626.60\n",
      "Reward: 975.05, Ewma Reward: 630.08\n",
      "Reward: 805.44, Ewma Reward: 631.84\n",
      "Reward: 600.12, Ewma Reward: 631.52\n",
      "Reward: 675.26, Ewma Reward: 631.96\n",
      "Reward: -136.48, Ewma Reward: 624.27\n",
      "Reward: 548.47, Ewma Reward: 623.51\n",
      "Reward: 686.72, Ewma Reward: 624.15\n",
      "Reward: 215.65, Ewma Reward: 620.06\n",
      "Reward: 274.45, Ewma Reward: 616.60\n",
      "Reward: 241.00, Ewma Reward: 612.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 628          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 884          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 528          |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015488681 |\n",
      "|    clip_fraction        | 0.00231      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -7.03e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 416          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000117    |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 807          |\n",
      "------------------------------------------\n",
      "Reward: 127.27, Ewma Reward: 607.99\n",
      "Reward: 906.51, Ewma Reward: 610.98\n",
      "Reward: 900.90, Ewma Reward: 613.88\n",
      "Reward: 697.95, Ewma Reward: 614.72\n",
      "Reward: -21.74, Ewma Reward: 608.35\n",
      "Reward: 1231.71, Ewma Reward: 614.59\n",
      "Reward: -200.79, Ewma Reward: 606.43\n",
      "Reward: 486.05, Ewma Reward: 605.23\n",
      "Reward: 1178.21, Ewma Reward: 610.96\n",
      "Reward: -221.40, Ewma Reward: 602.64\n",
      "Reward: 1069.34, Ewma Reward: 607.30\n",
      "Reward: 556.59, Ewma Reward: 606.80\n",
      "Reward: 578.77, Ewma Reward: 606.51\n",
      "Reward: 266.98, Ewma Reward: 603.12\n",
      "Reward: 186.78, Ewma Reward: 598.96\n",
      "Reward: 1422.34, Ewma Reward: 607.19\n",
      "Reward: 793.31, Ewma Reward: 609.05\n",
      "Reward: 855.74, Ewma Reward: 611.52\n",
      "Reward: 192.81, Ewma Reward: 607.33\n",
      "Reward: 536.54, Ewma Reward: 606.62\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 596          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 535          |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019837248 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.0169       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 262          |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000911    |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 527          |\n",
      "------------------------------------------\n",
      "Reward: 131.22, Ewma Reward: 601.87\n",
      "Reward: 369.08, Ewma Reward: 599.54\n",
      "Reward: 1467.26, Ewma Reward: 608.22\n",
      "Reward: 583.13, Ewma Reward: 607.97\n",
      "Reward: 814.57, Ewma Reward: 610.03\n",
      "Reward: 954.96, Ewma Reward: 613.48\n",
      "Reward: 749.74, Ewma Reward: 614.85\n",
      "Reward: 51.82, Ewma Reward: 609.21\n",
      "Reward: 136.71, Ewma Reward: 604.49\n",
      "Reward: 220.67, Ewma Reward: 600.65\n",
      "Reward: 650.63, Ewma Reward: 601.15\n",
      "Reward: 264.54, Ewma Reward: 597.79\n",
      "Reward: 515.21, Ewma Reward: 596.96\n",
      "Reward: 1324.50, Ewma Reward: 604.23\n",
      "Reward: 1185.45, Ewma Reward: 610.05\n",
      "Reward: 1198.95, Ewma Reward: 615.94\n",
      "Reward: -375.76, Ewma Reward: 606.02\n",
      "Reward: 151.47, Ewma Reward: 601.47\n",
      "Reward: 163.23, Ewma Reward: 597.09\n",
      "Reward: 1272.20, Ewma Reward: 603.84\n",
      "Reward: 268.76, Ewma Reward: 600.49\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 595        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 886        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 545        |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00209588 |\n",
      "|    clip_fraction        | 0.00143    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | -0.000314  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 293        |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.000168  |\n",
      "|    std                  | 0.933      |\n",
      "|    value_loss           | 598        |\n",
      "----------------------------------------\n",
      "Reward: 950.46, Ewma Reward: 603.99\n",
      "Reward: 511.63, Ewma Reward: 603.07\n",
      "Reward: 632.15, Ewma Reward: 603.36\n",
      "Reward: 1044.39, Ewma Reward: 607.77\n",
      "Reward: 28.27, Ewma Reward: 601.97\n",
      "Reward: 312.20, Ewma Reward: 599.08\n",
      "Reward: 830.58, Ewma Reward: 601.39\n",
      "Reward: 1222.83, Ewma Reward: 607.61\n",
      "Reward: -83.01, Ewma Reward: 600.70\n",
      "Reward: 602.57, Ewma Reward: 600.72\n",
      "Reward: 311.00, Ewma Reward: 597.82\n",
      "Reward: 239.01, Ewma Reward: 594.23\n",
      "Reward: 840.00, Ewma Reward: 596.69\n",
      "Reward: 1082.46, Ewma Reward: 601.55\n",
      "Reward: 1116.93, Ewma Reward: 606.70\n",
      "Reward: 399.56, Ewma Reward: 604.63\n",
      "Reward: 1494.88, Ewma Reward: 613.53\n",
      "Reward: -195.25, Ewma Reward: 605.45\n",
      "Reward: 526.96, Ewma Reward: 604.66\n",
      "Reward: 654.97, Ewma Reward: 605.16\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 588          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 554          |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033746464 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.000101    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 343          |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000881    |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 703          |\n",
      "------------------------------------------\n",
      "Reward: 927.96, Ewma Reward: 608.39\n",
      "Reward: 1205.90, Ewma Reward: 614.37\n",
      "Reward: 212.35, Ewma Reward: 610.35\n",
      "Reward: 540.81, Ewma Reward: 609.65\n",
      "Reward: 1153.60, Ewma Reward: 615.09\n",
      "Reward: 704.85, Ewma Reward: 615.99\n",
      "Reward: 491.55, Ewma Reward: 614.74\n",
      "Reward: 1039.56, Ewma Reward: 618.99\n",
      "Reward: 111.44, Ewma Reward: 613.92\n",
      "Reward: 1170.98, Ewma Reward: 619.49\n",
      "Reward: 942.51, Ewma Reward: 622.72\n",
      "Reward: 219.68, Ewma Reward: 618.69\n",
      "Reward: 511.18, Ewma Reward: 617.61\n",
      "Reward: 1496.15, Ewma Reward: 626.40\n",
      "Reward: 547.92, Ewma Reward: 625.61\n",
      "Reward: -13.99, Ewma Reward: 619.22\n",
      "Reward: 1563.94, Ewma Reward: 628.66\n",
      "Reward: 6.26, Ewma Reward: 622.44\n",
      "Reward: 1060.92, Ewma Reward: 626.82\n",
      "Reward: 796.02, Ewma Reward: 628.52\n",
      "Reward: 915.32, Ewma Reward: 631.38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 616         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 886         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002669908 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.00282     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00066    |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 639         |\n",
      "-----------------------------------------\n",
      "Reward: 496.12, Ewma Reward: 630.03\n",
      "Reward: 625.67, Ewma Reward: 629.99\n",
      "Reward: 514.91, Ewma Reward: 628.84\n",
      "Reward: -69.99, Ewma Reward: 621.85\n",
      "Reward: 62.69, Ewma Reward: 616.26\n",
      "Reward: -36.63, Ewma Reward: 609.73\n",
      "Reward: 441.44, Ewma Reward: 608.05\n",
      "Reward: 1301.00, Ewma Reward: 614.98\n",
      "Reward: 862.19, Ewma Reward: 617.45\n",
      "Reward: 69.98, Ewma Reward: 611.97\n",
      "Reward: 1416.48, Ewma Reward: 620.02\n",
      "Reward: 384.02, Ewma Reward: 617.66\n",
      "Reward: 1451.56, Ewma Reward: 626.00\n",
      "Reward: 610.79, Ewma Reward: 625.84\n",
      "Reward: 340.03, Ewma Reward: 622.99\n",
      "Reward: 198.17, Ewma Reward: 618.74\n",
      "Reward: 67.89, Ewma Reward: 613.23\n",
      "Reward: 832.71, Ewma Reward: 615.42\n",
      "Reward: 635.92, Ewma Reward: 615.63\n",
      "Reward: 560.95, Ewma Reward: 615.08\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 615          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 573          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024771132 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.00706      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 818          |\n",
      "------------------------------------------\n",
      "Reward: -146.73, Ewma Reward: 607.46\n",
      "Reward: -267.44, Ewma Reward: 598.72\n",
      "Reward: 493.11, Ewma Reward: 597.66\n",
      "Reward: 1327.91, Ewma Reward: 604.96\n",
      "Reward: 131.07, Ewma Reward: 600.22\n",
      "Reward: -501.60, Ewma Reward: 589.20\n",
      "Reward: 472.49, Ewma Reward: 588.04\n",
      "Reward: 767.77, Ewma Reward: 589.83\n",
      "Reward: 458.67, Ewma Reward: 588.52\n",
      "Reward: 982.33, Ewma Reward: 592.46\n",
      "Reward: 1399.92, Ewma Reward: 600.54\n",
      "Reward: 1153.51, Ewma Reward: 606.07\n",
      "Reward: 155.94, Ewma Reward: 601.56\n",
      "Reward: 758.47, Ewma Reward: 603.13\n",
      "Reward: -303.31, Ewma Reward: 594.07\n",
      "Reward: 88.40, Ewma Reward: 589.01\n",
      "Reward: 423.25, Ewma Reward: 587.35\n",
      "Reward: 168.47, Ewma Reward: 583.17\n",
      "Reward: 48.31, Ewma Reward: 577.82\n",
      "Reward: 413.28, Ewma Reward: 576.17\n",
      "Reward: 704.39, Ewma Reward: 577.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 578          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 581          |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023502114 |\n",
      "|    clip_fraction        | 0.00841      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.00371     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 280          |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000572    |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 548          |\n",
      "------------------------------------------\n",
      "Reward: 1204.17, Ewma Reward: 583.72\n",
      "Reward: 325.52, Ewma Reward: 581.14\n",
      "Reward: 52.38, Ewma Reward: 575.85\n",
      "Reward: 1073.44, Ewma Reward: 580.83\n",
      "Reward: -197.54, Ewma Reward: 573.04\n",
      "Reward: 1221.14, Ewma Reward: 579.52\n",
      "Reward: 612.03, Ewma Reward: 579.85\n",
      "Reward: 629.95, Ewma Reward: 580.35\n",
      "Reward: -503.69, Ewma Reward: 569.51\n",
      "Reward: 279.84, Ewma Reward: 566.61\n",
      "Reward: 1026.70, Ewma Reward: 571.21\n",
      "Reward: 222.76, Ewma Reward: 567.73\n",
      "Reward: 205.32, Ewma Reward: 564.11\n",
      "Reward: 717.55, Ewma Reward: 565.64\n",
      "Reward: 935.02, Ewma Reward: 569.33\n",
      "Reward: 720.55, Ewma Reward: 570.85\n",
      "Reward: 250.39, Ewma Reward: 567.64\n",
      "Reward: 297.95, Ewma Reward: 564.94\n",
      "Reward: -62.43, Ewma Reward: 558.67\n",
      "Reward: -47.02, Ewma Reward: 552.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 551          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 590          |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011498455 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 5.97e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 288          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 600          |\n",
      "------------------------------------------\n",
      "Reward: 132.25, Ewma Reward: 548.41\n",
      "Reward: 143.61, Ewma Reward: 544.36\n",
      "Reward: 76.95, Ewma Reward: 539.69\n",
      "Reward: 1.48, Ewma Reward: 534.31\n",
      "Reward: 204.29, Ewma Reward: 531.01\n",
      "Reward: 113.89, Ewma Reward: 526.84\n",
      "Reward: 1192.89, Ewma Reward: 533.50\n",
      "Reward: 1311.42, Ewma Reward: 541.27\n",
      "Reward: 1319.22, Ewma Reward: 549.05\n",
      "Reward: 669.79, Ewma Reward: 550.26\n",
      "Reward: 775.60, Ewma Reward: 552.52\n",
      "Reward: 450.89, Ewma Reward: 551.50\n",
      "Reward: -127.13, Ewma Reward: 544.71\n",
      "Reward: 516.88, Ewma Reward: 544.43\n",
      "Reward: 505.30, Ewma Reward: 544.04\n",
      "Reward: 1045.12, Ewma Reward: 549.05\n",
      "Reward: 697.19, Ewma Reward: 550.53\n",
      "Reward: 1122.85, Ewma Reward: 556.26\n",
      "Reward: 862.37, Ewma Reward: 559.32\n",
      "Reward: 1444.01, Ewma Reward: 568.17\n",
      "Reward: 603.21, Ewma Reward: 568.52\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 548        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 888        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 599        |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00215141 |\n",
      "|    clip_fraction        | 0.019      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.00837    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 262        |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.00122   |\n",
      "|    std                  | 0.955      |\n",
      "|    value_loss           | 509        |\n",
      "----------------------------------------\n",
      "Reward: 1030.20, Ewma Reward: 573.13\n",
      "Reward: 47.80, Ewma Reward: 567.88\n",
      "Reward: 956.92, Ewma Reward: 571.77\n",
      "Reward: 587.26, Ewma Reward: 571.93\n",
      "Reward: 857.67, Ewma Reward: 574.78\n",
      "Reward: 199.44, Ewma Reward: 571.03\n",
      "Reward: 972.79, Ewma Reward: 575.05\n",
      "Reward: 98.67, Ewma Reward: 570.28\n",
      "Reward: 285.74, Ewma Reward: 567.44\n",
      "Reward: 488.73, Ewma Reward: 566.65\n",
      "Reward: 531.98, Ewma Reward: 566.30\n",
      "Reward: 783.50, Ewma Reward: 568.48\n",
      "Reward: 413.70, Ewma Reward: 566.93\n",
      "Reward: 358.77, Ewma Reward: 564.85\n",
      "Reward: 776.74, Ewma Reward: 566.97\n",
      "Reward: 599.44, Ewma Reward: 567.29\n",
      "Reward: 878.70, Ewma Reward: 570.40\n",
      "Reward: 709.97, Ewma Reward: 571.80\n",
      "Reward: 1279.59, Ewma Reward: 578.88\n",
      "Reward: 982.58, Ewma Reward: 582.92\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 532          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 607          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023615062 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.0218       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 333          |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.000459    |\n",
      "|    std                  | 0.955        |\n",
      "|    value_loss           | 686          |\n",
      "------------------------------------------\n",
      "Reward: 256.24, Ewma Reward: 579.65\n",
      "Reward: 1003.60, Ewma Reward: 583.89\n",
      "Reward: -189.18, Ewma Reward: 576.16\n",
      "Reward: 204.07, Ewma Reward: 572.44\n",
      "Reward: 4.65, Ewma Reward: 566.76\n",
      "Reward: 1117.93, Ewma Reward: 572.27\n",
      "Reward: 781.80, Ewma Reward: 574.37\n",
      "Reward: 1099.32, Ewma Reward: 579.62\n",
      "Reward: 1323.63, Ewma Reward: 587.06\n",
      "Reward: 729.96, Ewma Reward: 588.48\n",
      "Reward: 522.31, Ewma Reward: 587.82\n",
      "Reward: 384.63, Ewma Reward: 585.79\n",
      "Reward: 863.53, Ewma Reward: 588.57\n",
      "Reward: 537.31, Ewma Reward: 588.06\n",
      "Reward: 46.21, Ewma Reward: 582.64\n",
      "Reward: 903.86, Ewma Reward: 585.85\n",
      "Reward: 680.62, Ewma Reward: 586.80\n",
      "Reward: -77.50, Ewma Reward: 580.15\n",
      "Reward: -388.93, Ewma Reward: 570.46\n",
      "Reward: 483.98, Ewma Reward: 569.60\n",
      "Reward: 253.51, Ewma Reward: 566.44\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 541          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 617          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038131813 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.00834      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 225          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00077     |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 473          |\n",
      "------------------------------------------\n",
      "Reward: 148.49, Ewma Reward: 562.26\n",
      "Reward: 522.36, Ewma Reward: 561.86\n",
      "Reward: 263.60, Ewma Reward: 558.88\n",
      "Reward: 503.60, Ewma Reward: 558.32\n",
      "Reward: 1064.24, Ewma Reward: 563.38\n",
      "Reward: 105.97, Ewma Reward: 558.81\n",
      "Reward: 1578.64, Ewma Reward: 569.01\n",
      "Reward: 737.49, Ewma Reward: 570.69\n",
      "Reward: 641.06, Ewma Reward: 571.40\n",
      "Reward: 681.45, Ewma Reward: 572.50\n",
      "Reward: 659.63, Ewma Reward: 573.37\n",
      "Reward: 554.67, Ewma Reward: 573.18\n",
      "Reward: 586.45, Ewma Reward: 573.31\n",
      "Reward: 374.19, Ewma Reward: 571.32\n",
      "Reward: 156.40, Ewma Reward: 567.17\n",
      "Reward: 951.15, Ewma Reward: 571.01\n",
      "Reward: 551.48, Ewma Reward: 570.82\n",
      "Reward: -166.18, Ewma Reward: 563.45\n",
      "Reward: 1388.04, Ewma Reward: 571.69\n",
      "Reward: 1163.12, Ewma Reward: 577.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 563          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 889          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 626          |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046845833 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 283          |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 564          |\n",
      "------------------------------------------\n",
      "Reward: 273.45, Ewma Reward: 574.57\n",
      "Reward: 973.42, Ewma Reward: 578.55\n",
      "Reward: 378.95, Ewma Reward: 576.56\n",
      "Reward: 607.15, Ewma Reward: 576.86\n",
      "Reward: 1235.51, Ewma Reward: 583.45\n",
      "Reward: 1001.92, Ewma Reward: 587.64\n",
      "Reward: 779.81, Ewma Reward: 589.56\n",
      "Reward: 1147.17, Ewma Reward: 595.13\n",
      "Reward: 1518.10, Ewma Reward: 604.36\n",
      "Reward: 376.35, Ewma Reward: 602.08\n",
      "Reward: 698.03, Ewma Reward: 603.04\n",
      "Reward: 1006.01, Ewma Reward: 607.07\n",
      "Reward: 450.06, Ewma Reward: 605.50\n",
      "Reward: 1358.44, Ewma Reward: 613.03\n",
      "Reward: 311.75, Ewma Reward: 610.02\n",
      "Reward: 1209.74, Ewma Reward: 616.02\n",
      "Reward: 868.21, Ewma Reward: 618.54\n",
      "Reward: 140.29, Ewma Reward: 613.76\n",
      "Reward: 850.49, Ewma Reward: 616.12\n",
      "Reward: 1153.56, Ewma Reward: 621.50\n",
      "Reward: 355.28, Ewma Reward: 618.83\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 653         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 888         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002193564 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 288         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 587         |\n",
      "-----------------------------------------\n",
      "Reward: 906.12, Ewma Reward: 621.71\n",
      "Reward: 186.09, Ewma Reward: 617.35\n",
      "Reward: 1092.84, Ewma Reward: 622.11\n",
      "Reward: 134.36, Ewma Reward: 617.23\n",
      "Reward: 26.41, Ewma Reward: 611.32\n",
      "Reward: 312.18, Ewma Reward: 608.33\n",
      "Reward: 629.37, Ewma Reward: 608.54\n",
      "Reward: 561.74, Ewma Reward: 608.07\n",
      "Reward: 173.89, Ewma Reward: 603.73\n",
      "Reward: 462.46, Ewma Reward: 602.32\n",
      "Reward: 22.55, Ewma Reward: 596.52\n",
      "Reward: 851.84, Ewma Reward: 599.07\n",
      "Reward: 688.83, Ewma Reward: 599.97\n",
      "Reward: 1383.74, Ewma Reward: 607.81\n",
      "Reward: -347.48, Ewma Reward: 598.26\n",
      "Reward: 523.43, Ewma Reward: 597.51\n",
      "Reward: -65.15, Ewma Reward: 590.88\n",
      "Reward: 1327.64, Ewma Reward: 598.25\n",
      "Reward: 60.89, Ewma Reward: 592.87\n",
      "Reward: 819.09, Ewma Reward: 595.14\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 612          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 887          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 645          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025778534 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0026       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 393          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.000315    |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 790          |\n",
      "------------------------------------------\n",
      "Reward: -229.92, Ewma Reward: 586.89\n",
      "Reward: 949.86, Ewma Reward: 590.52\n",
      "Reward: 822.16, Ewma Reward: 592.83\n",
      "Reward: -62.04, Ewma Reward: 586.28\n",
      "Reward: 686.88, Ewma Reward: 587.29\n",
      "Reward: 1309.04, Ewma Reward: 594.51\n",
      "Reward: 890.81, Ewma Reward: 597.47\n",
      "Reward: 951.28, Ewma Reward: 601.01\n",
      "Reward: 527.31, Ewma Reward: 600.27\n",
      "Reward: 1204.49, Ewma Reward: 606.31\n",
      "Reward: 349.05, Ewma Reward: 603.74\n",
      "Reward: 79.91, Ewma Reward: 598.50\n",
      "Reward: 1103.43, Ewma Reward: 603.55\n",
      "Reward: 121.18, Ewma Reward: 598.73\n",
      "Reward: 872.78, Ewma Reward: 601.47\n",
      "Reward: -130.19, Ewma Reward: 594.15\n",
      "Reward: 1082.65, Ewma Reward: 599.04\n",
      "Reward: 902.47, Ewma Reward: 602.07\n",
      "Reward: 461.04, Ewma Reward: 600.66\n",
      "Reward: 777.34, Ewma Reward: 602.43\n",
      "Reward: 1157.32, Ewma Reward: 607.98\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 622          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 888          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 581632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023542992 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00581      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000889    |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 519          |\n",
      "------------------------------------------\n",
      "Reward: 543.54, Ewma Reward: 607.33\n",
      "Reward: 864.82, Ewma Reward: 609.91\n",
      "Reward: 1359.37, Ewma Reward: 617.40\n",
      "Reward: 1104.51, Ewma Reward: 622.27\n",
      "Reward: 704.15, Ewma Reward: 623.09\n",
      "Reward: 1106.59, Ewma Reward: 627.93\n",
      "Reward: 227.66, Ewma Reward: 623.92\n",
      "Reward: 1062.07, Ewma Reward: 628.31\n",
      "Reward: 271.88, Ewma Reward: 624.74\n",
      "Reward: 952.58, Ewma Reward: 628.02\n",
      "Reward: 606.61, Ewma Reward: 627.81\n",
      "Reward: 137.28, Ewma Reward: 622.90\n",
      "Reward: 1095.28, Ewma Reward: 627.62\n",
      "Reward: 515.61, Ewma Reward: 626.50\n",
      "Reward: 1304.75, Ewma Reward: 633.29\n",
      "Reward: 1093.60, Ewma Reward: 637.89\n",
      "Reward: 1095.41, Ewma Reward: 642.46\n",
      "Reward: 827.23, Ewma Reward: 644.31\n",
      "Reward: 612.01, Ewma Reward: 643.99\n",
      "Reward: 1177.38, Ewma Reward: 649.32\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 687           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 889           |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 663           |\n",
      "|    total_timesteps      | 589824        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031846578 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.36         |\n",
      "|    explained_variance   | 0.0129        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 325           |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | 1.18e-06      |\n",
      "|    std                  | 0.946         |\n",
      "|    value_loss           | 670           |\n",
      "-------------------------------------------\n",
      "Reward: 1439.85, Ewma Reward: 657.23\n",
      "Reward: 31.70, Ewma Reward: 650.97\n",
      "Reward: 402.57, Ewma Reward: 648.49\n",
      "Reward: 1021.66, Ewma Reward: 652.22\n",
      "Reward: 1411.50, Ewma Reward: 659.81\n",
      "Reward: 617.55, Ewma Reward: 659.39\n",
      "Reward: 677.36, Ewma Reward: 659.57\n",
      "Reward: 514.51, Ewma Reward: 658.12\n",
      "Reward: 464.05, Ewma Reward: 656.18\n",
      "Reward: 1060.17, Ewma Reward: 660.22\n",
      "Reward: 307.45, Ewma Reward: 656.69\n",
      "Reward: 124.84, Ewma Reward: 651.37\n",
      "Reward: 147.63, Ewma Reward: 646.34\n",
      "Reward: 164.99, Ewma Reward: 641.52\n",
      "Reward: 1134.23, Ewma Reward: 646.45\n",
      "Reward: 841.32, Ewma Reward: 648.40\n",
      "Reward: 426.77, Ewma Reward: 646.18\n",
      "Reward: -151.92, Ewma Reward: 638.20\n",
      "Reward: 1316.87, Ewma Reward: 644.99\n",
      "Reward: 307.25, Ewma Reward: 641.61\n",
      "Reward: 809.00, Ewma Reward: 643.28\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 684          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 891          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025587243 |\n",
      "|    clip_fraction        | 0.00131      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00017      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 409          |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.000173    |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 828          |\n",
      "------------------------------------------\n",
      "Reward: 839.72, Ewma Reward: 645.25\n",
      "Reward: 589.05, Ewma Reward: 644.69\n",
      "Reward: 123.59, Ewma Reward: 639.48\n",
      "Reward: 679.34, Ewma Reward: 639.87\n",
      "Reward: 710.22, Ewma Reward: 640.58\n",
      "Reward: 381.75, Ewma Reward: 637.99\n",
      "Reward: 1168.17, Ewma Reward: 643.29\n",
      "Reward: 22.19, Ewma Reward: 637.08\n",
      "Reward: 1154.88, Ewma Reward: 642.26\n",
      "Reward: 201.81, Ewma Reward: 637.85\n",
      "Reward: 129.14, Ewma Reward: 632.77\n",
      "Reward: 1102.42, Ewma Reward: 637.46\n",
      "Reward: -187.19, Ewma Reward: 629.22\n",
      "Reward: 242.74, Ewma Reward: 625.35\n",
      "Reward: 129.45, Ewma Reward: 620.39\n",
      "Reward: 645.13, Ewma Reward: 620.64\n",
      "Reward: 487.30, Ewma Reward: 619.31\n",
      "Reward: 650.43, Ewma Reward: 619.62\n",
      "Reward: 833.79, Ewma Reward: 621.76\n",
      "Reward: 499.73, Ewma Reward: 620.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 626         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 892         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004014992 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -8.87e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 274         |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 559         |\n",
      "-----------------------------------------\n",
      "Reward: 147.43, Ewma Reward: 615.81\n",
      "Reward: 692.33, Ewma Reward: 616.57\n",
      "Reward: 230.77, Ewma Reward: 612.72\n",
      "Reward: 60.81, Ewma Reward: 607.20\n",
      "Reward: 1357.84, Ewma Reward: 614.70\n",
      "Reward: 358.30, Ewma Reward: 612.14\n",
      "Reward: 948.09, Ewma Reward: 615.50\n",
      "Reward: 999.60, Ewma Reward: 619.34\n",
      "Reward: -57.71, Ewma Reward: 612.57\n",
      "Reward: 792.95, Ewma Reward: 614.37\n",
      "Reward: 545.58, Ewma Reward: 613.68\n",
      "Reward: 378.43, Ewma Reward: 611.33\n",
      "Reward: 215.84, Ewma Reward: 607.38\n",
      "Reward: 1692.18, Ewma Reward: 618.23\n",
      "Reward: 888.99, Ewma Reward: 620.93\n",
      "Reward: 414.70, Ewma Reward: 618.87\n",
      "Reward: 71.53, Ewma Reward: 613.40\n",
      "Reward: 84.01, Ewma Reward: 608.10\n",
      "Reward: 299.09, Ewma Reward: 605.01\n",
      "Reward: 765.10, Ewma Reward: 606.61\n",
      "Reward: 496.37, Ewma Reward: 605.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 638          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 684          |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010561461 |\n",
      "|    clip_fraction        | 0.00162      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.000237     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 202          |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000242    |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 415          |\n",
      "------------------------------------------\n",
      "Reward: 1558.79, Ewma Reward: 615.04\n",
      "Reward: 1208.35, Ewma Reward: 620.98\n",
      "Reward: 173.38, Ewma Reward: 616.50\n",
      "Reward: -150.53, Ewma Reward: 608.83\n",
      "Reward: 512.39, Ewma Reward: 607.87\n",
      "Reward: 1233.18, Ewma Reward: 614.12\n",
      "Reward: 1523.59, Ewma Reward: 623.21\n",
      "Reward: 870.85, Ewma Reward: 625.69\n",
      "Reward: 847.41, Ewma Reward: 627.91\n",
      "Reward: 1300.14, Ewma Reward: 634.63\n",
      "Reward: 516.85, Ewma Reward: 633.45\n",
      "Reward: 602.70, Ewma Reward: 633.14\n",
      "Reward: 807.30, Ewma Reward: 634.89\n",
      "Reward: 449.08, Ewma Reward: 633.03\n",
      "Reward: 213.31, Ewma Reward: 628.83\n",
      "Reward: 70.54, Ewma Reward: 623.25\n",
      "Reward: 624.20, Ewma Reward: 623.26\n",
      "Reward: 30.51, Ewma Reward: 617.33\n",
      "Reward: -646.88, Ewma Reward: 604.69\n",
      "Reward: 392.84, Ewma Reward: 602.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 622         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 692         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004115387 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.000291    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 283         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 553         |\n",
      "-----------------------------------------\n",
      "Reward: 820.88, Ewma Reward: 604.75\n",
      "Reward: 967.70, Ewma Reward: 608.38\n",
      "Reward: 148.18, Ewma Reward: 603.78\n",
      "Reward: 1295.40, Ewma Reward: 610.70\n",
      "Reward: 1088.73, Ewma Reward: 615.48\n",
      "Reward: 1059.97, Ewma Reward: 619.92\n",
      "Reward: 390.25, Ewma Reward: 617.63\n",
      "Reward: 1121.82, Ewma Reward: 622.67\n",
      "Reward: 493.33, Ewma Reward: 621.37\n",
      "Reward: 1368.03, Ewma Reward: 628.84\n",
      "Reward: 992.90, Ewma Reward: 632.48\n",
      "Reward: 971.75, Ewma Reward: 635.87\n",
      "Reward: -197.74, Ewma Reward: 627.54\n",
      "Reward: 237.35, Ewma Reward: 623.64\n",
      "Reward: 818.24, Ewma Reward: 625.58\n",
      "Reward: 1453.56, Ewma Reward: 633.86\n",
      "Reward: 769.78, Ewma Reward: 635.22\n",
      "Reward: 156.78, Ewma Reward: 630.44\n",
      "Reward: 723.15, Ewma Reward: 631.36\n",
      "Reward: 719.44, Ewma Reward: 632.24\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 609          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 900          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 700          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035417075 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.0039       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 382          |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.000728    |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 781          |\n",
      "------------------------------------------\n",
      "Reward: 960.71, Ewma Reward: 635.53\n",
      "Reward: 1238.25, Ewma Reward: 641.56\n",
      "Reward: 1401.89, Ewma Reward: 649.16\n",
      "Reward: 622.95, Ewma Reward: 648.90\n",
      "Reward: 221.48, Ewma Reward: 644.62\n",
      "Reward: 941.93, Ewma Reward: 647.60\n",
      "Reward: 202.01, Ewma Reward: 643.14\n",
      "Reward: 136.92, Ewma Reward: 638.08\n",
      "Reward: 524.16, Ewma Reward: 636.94\n",
      "Reward: 1298.98, Ewma Reward: 643.56\n",
      "Reward: 792.19, Ewma Reward: 645.05\n",
      "Reward: 922.41, Ewma Reward: 647.82\n",
      "Reward: 1462.25, Ewma Reward: 655.96\n",
      "Reward: 331.66, Ewma Reward: 652.72\n",
      "Reward: 500.50, Ewma Reward: 651.20\n",
      "Reward: 833.92, Ewma Reward: 653.03\n",
      "Reward: 363.16, Ewma Reward: 650.13\n",
      "Reward: 636.17, Ewma Reward: 649.99\n",
      "Reward: 325.18, Ewma Reward: 646.74\n",
      "Reward: 1420.30, Ewma Reward: 654.47\n",
      "Reward: 563.34, Ewma Reward: 653.56\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | 636           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 903           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 707           |\n",
      "|    total_timesteps      | 638976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034820533 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 0.00726       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 379           |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -7.73e-05     |\n",
      "|    std                  | 0.927         |\n",
      "|    value_loss           | 764           |\n",
      "-------------------------------------------\n",
      "Reward: 1539.41, Ewma Reward: 662.42\n",
      "Reward: 979.87, Ewma Reward: 665.60\n",
      "Reward: 1433.87, Ewma Reward: 673.28\n",
      "Reward: 1462.51, Ewma Reward: 681.17\n",
      "Reward: 457.14, Ewma Reward: 678.93\n",
      "Reward: 1175.68, Ewma Reward: 683.90\n",
      "Reward: 1195.32, Ewma Reward: 689.01\n",
      "Reward: -113.93, Ewma Reward: 680.98\n",
      "Reward: 400.90, Ewma Reward: 678.18\n",
      "Reward: 476.33, Ewma Reward: 676.16\n",
      "Reward: 704.63, Ewma Reward: 676.45\n",
      "Reward: 1025.72, Ewma Reward: 679.94\n",
      "Reward: 634.88, Ewma Reward: 679.49\n",
      "Reward: 842.29, Ewma Reward: 681.12\n",
      "Reward: 230.72, Ewma Reward: 676.61\n",
      "Reward: 645.55, Ewma Reward: 676.30\n",
      "Reward: 839.36, Ewma Reward: 677.93\n",
      "Reward: 1371.44, Ewma Reward: 684.87\n",
      "Reward: 660.23, Ewma Reward: 684.62\n",
      "Reward: 985.25, Ewma Reward: 687.63\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 707          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 904          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 715          |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013129881 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.00112      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 379          |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.000292    |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 750          |\n",
      "------------------------------------------\n",
      "Reward: 870.26, Ewma Reward: 689.46\n",
      "Reward: 643.78, Ewma Reward: 689.00\n",
      "Reward: 391.97, Ewma Reward: 686.03\n",
      "Reward: 381.91, Ewma Reward: 682.99\n",
      "Reward: 1017.53, Ewma Reward: 686.33\n",
      "Reward: 164.08, Ewma Reward: 681.11\n",
      "Reward: 1106.02, Ewma Reward: 685.36\n",
      "Reward: 1268.54, Ewma Reward: 691.19\n",
      "Reward: 1111.58, Ewma Reward: 695.40\n",
      "Reward: 919.57, Ewma Reward: 697.64\n",
      "Reward: 33.85, Ewma Reward: 691.00\n",
      "Reward: 1073.08, Ewma Reward: 694.82\n",
      "Reward: 397.60, Ewma Reward: 691.85\n",
      "Reward: -37.55, Ewma Reward: 684.55\n",
      "Reward: 803.88, Ewma Reward: 685.75\n",
      "Reward: 23.00, Ewma Reward: 679.12\n",
      "Reward: 315.59, Ewma Reward: 675.48\n",
      "Reward: -186.98, Ewma Reward: 666.86\n",
      "Reward: 1033.80, Ewma Reward: 670.53\n",
      "Reward: 1024.00, Ewma Reward: 674.06\n",
      "Reward: 672.87, Ewma Reward: 674.05\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 704          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 908          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 721          |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017312062 |\n",
      "|    clip_fraction        | 0.00276      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.00701      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 405          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.000214    |\n",
      "|    std                  | 0.927        |\n",
      "|    value_loss           | 827          |\n",
      "------------------------------------------\n",
      "Reward: 302.93, Ewma Reward: 670.34\n",
      "Reward: 499.19, Ewma Reward: 668.63\n",
      "Reward: 152.90, Ewma Reward: 663.47\n",
      "Reward: 300.96, Ewma Reward: 659.85\n",
      "Reward: 193.05, Ewma Reward: 655.18\n",
      "Reward: 1027.39, Ewma Reward: 658.90\n",
      "Reward: 1118.73, Ewma Reward: 663.50\n",
      "Reward: 1389.85, Ewma Reward: 670.76\n",
      "Reward: 436.94, Ewma Reward: 668.42\n",
      "Reward: 1208.06, Ewma Reward: 673.82\n",
      "Reward: 187.50, Ewma Reward: 668.96\n",
      "Reward: 457.28, Ewma Reward: 666.84\n",
      "Reward: 1179.33, Ewma Reward: 671.97\n",
      "Reward: 181.67, Ewma Reward: 667.06\n",
      "Reward: 1038.28, Ewma Reward: 670.77\n",
      "Reward: 926.67, Ewma Reward: 673.33\n",
      "Reward: 766.93, Ewma Reward: 674.27\n",
      "Reward: 63.97, Ewma Reward: 668.17\n",
      "Reward: 1080.02, Ewma Reward: 672.29\n",
      "Reward: 657.44, Ewma Reward: 672.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 725         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 909         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002498696 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.000176    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 597         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd4600a0340>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.learn(1600*410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import evaluation\n",
    "reward,_=evaluation.evaluate_policy(model3,env,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History length: 10\n",
      "Features: ['sent latency inflation', 'latency ratio', 'send ratio']\n",
      "Getting min obs for ['sent latency inflation', 'latency ratio', 'send ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/envs/IL/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "model3=PPO.load('model3.zip')\n",
    "env=gym.make('PccNs-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Observation spaces do not match: Box([-1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.\n -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.], [   10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10.\n 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.\n  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.], (30,), float32) != Box(-1.0, 10000.0, (30,), float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tools/DR/MyProject/gym/tri.ipynb 单元格 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimitation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m rollout\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m traj\u001b[39m=\u001b[39mrollout\u001b[39m.\u001b[39;49mrollout(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model3,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     env,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     rollout\u001b[39m.\u001b[39;49mmake_min_episodes(\u001b[39m60\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     rng\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mdefault_rng(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m/home/tools/DR/imitation/src/imitation/data/rollout.py:711\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(policy, venv, sample_until, rng, unwrap, exclude_infos, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrollout\u001b[39m(\n\u001b[1;32m    669\u001b[0m     policy: AnyPolicy,\n\u001b[1;32m    670\u001b[0m     venv: VecEnv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    678\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[types\u001b[39m.\u001b[39mTrajectoryWithRew]:\n\u001b[1;32m    679\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate policy rollouts.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \n\u001b[1;32m    681\u001b[0m \u001b[39m    This method is a wrapper of generate_trajectories that allows\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39m        should truncate if required.\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m     trajs \u001b[39m=\u001b[39m generate_trajectories(\n\u001b[1;32m    712\u001b[0m         policy,\n\u001b[1;32m    713\u001b[0m         venv,\n\u001b[1;32m    714\u001b[0m         sample_until,\n\u001b[1;32m    715\u001b[0m         rng\u001b[39m=\u001b[39;49mrng,\n\u001b[1;32m    716\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    717\u001b[0m     )\n\u001b[1;32m    718\u001b[0m     \u001b[39mif\u001b[39;00m unwrap:\n\u001b[1;32m    719\u001b[0m         trajs \u001b[39m=\u001b[39m [unwrap_traj(traj) \u001b[39mfor\u001b[39;00m traj \u001b[39min\u001b[39;00m trajs]\n",
      "File \u001b[0;32m/home/tools/DR/imitation/src/imitation/data/rollout.py:412\u001b[0m, in \u001b[0;36mgenerate_trajectories\u001b[0;34m(policy, venv, sample_until, rng, deterministic_policy)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_trajectories\u001b[39m(\n\u001b[1;32m    383\u001b[0m     policy: AnyPolicy,\n\u001b[1;32m    384\u001b[0m     venv: VecEnv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m     deterministic_policy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence[types\u001b[39m.\u001b[39mTrajectoryWithRew]:\n\u001b[1;32m    390\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate trajectory dictionaries from a policy and an environment.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m        should truncate if required.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m     get_actions \u001b[39m=\u001b[39m policy_to_callable(policy, venv, deterministic_policy)\n\u001b[1;32m    414\u001b[0m     \u001b[39m# Collect rollout tuples.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     trajectories \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/home/tools/DR/imitation/src/imitation/data/rollout.py:360\u001b[0m, in \u001b[0;36mpolicy_to_callable\u001b[0;34m(policy, venv, deterministic_policy)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39massert\u001b[39;00m policy_obs_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(venv_obs_shape) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(policy_obs_shape) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    361\u001b[0m venv_obs_rearranged \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m     venv_obs_shape[\u001b[39m2\u001b[39m],\n\u001b[1;32m    363\u001b[0m     venv_obs_shape[\u001b[39m0\u001b[39m],\n\u001b[1;32m    364\u001b[0m     venv_obs_shape[\u001b[39m1\u001b[39m],\n\u001b[1;32m    365\u001b[0m )\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m venv_obs_rearranged \u001b[39m!=\u001b[39m policy_obs_shape:\n",
      "File \u001b[0;32m/home/tools/DR/imitation/src/imitation/data/rollout.py:347\u001b[0m, in \u001b[0;36mpolicy_to_callable\u001b[0;34m(policy, venv, deterministic_policy)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(policy, BaseAlgorithm):\n\u001b[1;32m    345\u001b[0m     \u001b[39m# Check that the observation and action spaces of policy and environment match\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m         check_for_correct_spaces(\n\u001b[1;32m    348\u001b[0m             venv,\n\u001b[1;32m    349\u001b[0m             policy\u001b[39m.\u001b[39;49mobservation_space,\n\u001b[1;32m    350\u001b[0m             policy\u001b[39m.\u001b[39;49maction_space,\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    352\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    353\u001b[0m         \u001b[39m# Check for a particularly common mistake when using image environments.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m         venv_obs_shape \u001b[39m=\u001b[39m venv\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/home/data/envs/IL/lib/python3.8/site-packages/stable_baselines3/common/utils.py:229\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39mChecks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39mspaces match after loading the model with given env.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m:param action_space: Action space to check against\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m observation_space \u001b[39m!=\u001b[39m env\u001b[39m.\u001b[39mobservation_space:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mObservation spaces do not match: \u001b[39m\u001b[39m{\u001b[39;00mobservation_space\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00menv\u001b[39m.\u001b[39mobservation_space\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m action_space \u001b[39m!=\u001b[39m env\u001b[39m.\u001b[39maction_space:\n\u001b[1;32m    231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction spaces do not match: \u001b[39m\u001b[39m{\u001b[39;00maction_space\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00menv\u001b[39m.\u001b[39maction_space\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Observation spaces do not match: Box([-1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.\n -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.], [   10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10.\n 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.\n  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.], (30,), float32) != Box(-1.0, 10000.0, (30,), float32)"
     ]
    }
   ],
   "source": [
    "from imitation.data import rollout\n",
    "import numpy as np\n",
    "\n",
    "traj=rollout.rollout(\n",
    "    model3,\n",
    "    env,\n",
    "    rollout.make_min_episodes(60),\n",
    "    rng=np.random.default_rng(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.\n",
       " -1.  1.  0. -1.  1.  0. -1.  1.  0. -1.  1.  0.], [   10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10.\n",
       " 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.\n",
       "  1000.    10. 10000.  1000.    10. 10000.  1000.    10. 10000.  1000.], (30,), float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment `PccNs` doesn't exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tools/DR/MyProject/gym/tri.ipynb 单元格 15\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimitation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m make_vec_env\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimitation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m RolloutInfoWrapper\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m venv\u001b[39m=\u001b[39mmake_vec_env(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mPccNs-v0\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     rng\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mdefault_rng(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     n_envs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     post_wrappers\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m env,_:RolloutInfoWrapper(env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tools/DR/MyProject/gym/tri.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[0;32m/home/tools/DR/imitation/src/imitation/util/util.py:117\u001b[0m, in \u001b[0;36mmake_vec_env\u001b[0;34m(env_name, rng, n_envs, parallel, log_dir, max_episode_steps, post_wrappers, env_make_kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes a vectorized environment.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    A VecEnv initialized with `n_envs` environments.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# Resolve the spec outside of the subprocess first, so that it is available to\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m# subprocesses running `make_env` via automatic pickling.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# Just to ensure packages are imported and spec is properly resolved\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m tmp_env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(env_name)\n\u001b[1;32m    118\u001b[0m tmp_env\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    119\u001b[0m spec \u001b[39m=\u001b[39m tmp_env\u001b[39m.\u001b[39mspec\n",
      "File \u001b[0;32m/home/data/envs/IL/lib/python3.8/site-packages/gymnasium/envs/registration.py:741\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    740\u001b[0m     \u001b[39m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     env_spec \u001b[39m=\u001b[39m _find_spec(\u001b[39mid\u001b[39;49m)\n\u001b[1;32m    743\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(env_spec, EnvSpec)\n\u001b[1;32m    745\u001b[0m \u001b[39m# Update the env spec kwargs with the `make` kwargs\u001b[39;00m\n",
      "File \u001b[0;32m/home/data/envs/IL/lib/python3.8/site-packages/gymnasium/envs/registration.py:527\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    521\u001b[0m     logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    522\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00menv_name\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m env_spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     _check_version_exists(ns, name, version)\n\u001b[1;32m    528\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\n\u001b[1;32m    529\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00menv_name\u001b[39m}\u001b[39;00m\u001b[39m. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[39mreturn\u001b[39;00m env_spec\n",
      "File \u001b[0;32m/home/data/envs/IL/lib/python3.8/site-packages/gymnasium/envs/registration.py:393\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m _check_name_exists(ns, name)\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/home/data/envs/IL/lib/python3.8/site-packages/gymnasium/envs/registration.py:370\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    367\u001b[0m namespace_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in namespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ns \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Did you mean: `\u001b[39m\u001b[39m{\u001b[39;00msuggestion[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m`?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m suggestion \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNameNotFound(\n\u001b[1;32m    371\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment `\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m` doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist\u001b[39m\u001b[39m{\u001b[39;00mnamespace_msg\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n",
      "\u001b[0;31mNameNotFound\u001b[0m: Environment `PccNs` doesn't exist."
     ]
    }
   ],
   "source": [
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "\n",
    "venv=make_vec_env(\n",
    "    'PccNs-v0',\n",
    "    rng=np.random.default_rng(),\n",
    "    n_envs=4,\n",
    "    post_wrappers=[\n",
    "        lambda env,_:RolloutInfoWrapper(env)\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
